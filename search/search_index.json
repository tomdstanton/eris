{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"<code>eris</code> \ud83e\uddec\ud83e\uddde\u200d\u2640\ud83d\udd2e\ufe0f","text":"<p>Uncovering IS-mediated discord in bacterial genomes</p> <p> </p>"},{"location":"#introduction","title":"Introduction \ud83c\udf10","text":"<p><code>eris</code> is a Python package for finding IS elements in bacterial genomes and quantifying their effect on other genes. IS elements are known to move, disrupt and even promote genes and whilst there are many tools to find IS elements in genomes, few attempt to report the resulting effects. </p> <p>Like many bioinformatics tools <code>eris</code> is designed to work from  the command-line, but is built on top of a robust API with few dependencies, and can be easily installed and incorporated into other programs, scripts and pipelines.</p>"},{"location":"#installation","title":"Installation \u2699\ufe0f","text":""},{"location":"#requires","title":"Requires \ud83e\uddf0","text":"<pre><code>python &gt;=3.9\nminimap2 &gt;=2.18\npyrodigal &gt;=3.5.0 (for ORF prediction only)\n</code></pre> <p>NOTE: eris is not yet on PyPI or Bioconda, please install from source until it is released</p>"},{"location":"#from-source","title":"From source:","text":"<pre><code># First clone the repo\ngit clone https://github.com/tomdstanton/eris.git &amp;&amp; cd eris\n# Then install with pip\npip install .  # -e for editable, developers only!\n# or install with pixi\npixi install\n</code></pre> <p>NOTE: For Pyrodigal, you should install the <code>orf</code> or <code>dev</code> environments with <code>pip</code> or <code>pixi</code></p> <pre><code># First clone the repo\ngit clone https://github.com/tomdstanton/eris.git &amp;&amp; cd eris\n# Then install with pip\npip install .[orf]  # -e for editable, developers only!\n# or install with pixi\npixi install -e orf\n</code></pre>"},{"location":"#usage","title":"Usage \ud83e\uddd1\u200d\ud83d\udcbb","text":"<p>The information below explains how to use the <code>eris</code> CLI.  For API usage, please refer to the reference documentation.</p>"},{"location":"#scan","title":"Scan \ud83d\udd0d","text":""},{"location":"#quickstart","title":"Quickstart","text":"<p><code>eris scan *.{fasta,gfa,gb} &gt; results.tsv</code></p>"},{"location":"#arguments","title":"Arguments","text":"<pre><code>usage: eris scan &lt;genome&gt; &lt;genome...&gt; [options]\n\n========================|&gt; eris |&gt;========================\n             Scan for IS in bacterial genomes             \n\nInputs:\n\n  Note, input file(s) may be compressed\n  Note, Genome(s) in FASTA/GFA format can paired up with GFA/BED\n  annotation files with the same prefix.\n\n  &lt;genome&gt;              Genome(s) in FASTA, GFA or Genbank format;\n                        reads from stdin by default.\n  -a [ ...], --annotations [ ...]\n                        Optional genome annotations in GFF3/BED format;\n                        These will be matched up to input genomes (FASTA/GFA) \n                        with corresponding filenames\n\nOutputs:\n\n  Note, text outputs accept \"-\" or \"stdout\" for stdout\n  If a directory is passed, individual files will be written per input genome\n\n  --tsv []              Path to output tabular results (default: stdout)\n  --ffn []              Path to output Feature DNA sequences in FASTA format;\n                        defaults to \"./[genome]_eris_results.ffn\" when passed without arguments.\n  --faa []              Path to output Feature Amino acid sequences in FASTA format;\n                        defaults to \"./[genome]_eris_results.faa\" when passed without arguments.\n  --no-tsv-header       Suppress header in TSV output\n\nOther options:\n\n  --progress            Show progress bar\n  -v, --version         Show version number and exit\n  -h, --help            Show this help message and exit\n\nFor more help, visit: eris.readthedocs.io\n</code></pre>"},{"location":"#the-algorithm","title":"The algorithm","text":"<ol> <li>Given a bacterial genome as an assembly (FASTA), assembly-graph (GFA) or annotation file (Genbank), the <code>scan</code> pipeline will align IS element nucleotide sequences from the ISFinder database against the  assembly contigs using minimap2.</li> <li>These alignments are then sorted by their target contig, and culled such that each region aligned contains the highest  scoring query.</li> <li>Each Element alignment is then considered to be a \"mobile-element\" Feature, and added to the list of Features on the respective contig.</li> <li>If the genome is from a sequence file (FASTA/GFA), ORFs are predicted with  Pyrodigal and CDS Features are added to each contig.</li> <li>The genome is then converted into a Feature graph, whereby Features on each contig, sorted by their respective start coordinates, are connected to their flanking Features; and if the contig is connected to other contigs  (GFA input), Features on the termini of connected contigs are also connected to each other.</li> <li>Promoters are searched for in each Element Feature using a regular expression. </li> <li>For each Element Feature, the Breadth-first search (BFS) algorithm traverses the Feature graph to find CDS that either overlap (part of the element) or flank the element.</li> <li>The relative effect of the Element on each flanking CDS Feature is predicted.</li> </ol>"},{"location":"#performance","title":"Performance","text":"<p><code>eris scan</code> is very fast, especially when providing annotations or once the  <code>pyrodigal.GeneFinder</code> instance has been trained (this occurs on the first input genome); it should only take &lt;1 second per assembly \ud83d\ude80</p>"},{"location":"#outputs","title":"Outputs","text":"<p>The main output of <code>eris scan</code> is the TSV tabular result which are written to <code>stdout</code> by default. Sequence information can be written to separate files via the respective CLI flags.</p>"},{"location":"#tsv-tabular-output","title":"TSV tabular output","text":"<p>The TSV tabular output reports one line per Feature of interest, which can either be the Element itself from the resulting alignments, the CDS inside the Element, or the CDS flanking the Element. If the context is the Element, information about the element from ISFinder will be reported. If the context is a CDS, information about the ORF/translation will be reported.</p> <p>The TSV columns are as follows:</p> <ol> <li>Genome: The name of the input genome.</li> <li>Feature: The unique identifier of the Feature in question.</li> <li>Type: The Feature type, currently only CDS are  supported if annotations are provided; Elements are annotated as \"<code>mobile_element</code>\" and promoters are annotated as \"<code>regulatory</code>\".</li> <li>Contig: The name of the contig the Element is on.</li> <li>Start: The start coordinate (0-based) of the Feature.</li> <li>End: The end coordinate of the Feature.</li> <li>Strand: The strand of the Feature (1 or -1).</li> <li>Partial: Whether the Feature overlaps with the start or end the contig.</li> <li>Element: The unique identifier of the Element from the current context.</li> <li>Element_distance: Signifies the distance of the Feature from the Element from the current context.</li> <li>Element_location: Signifies the relative location of the Element from the current context.</li> <li>Element_strand: Signifies the relative strand of the Element from the current context.</li> <li>Element_effect: Signifies the relative effect of the Element from the current context on the CDS.</li> <li>Percent_identity: The percent identity of the Element.</li> <li>Percent_coverage: The percent coverage of the Element.</li> <li>Name: The name of the Element if known (from ISFinder).</li> <li>Family: The family of the Element if known (from ISFinder).</li> <li>Group: The group of the Element if known (from ISFinder).</li> <li>Synonyms: The synonyms of the Element if known (from ISFinder).</li> <li>Origin: The origin of the Element if known (from ISFinder).</li> <li>IR: The relative location of the inverted repeat of the Element if known (from ISFinder).</li> <li>DR: The relative location of the direct repeat of the Element if known (from ISFinder).</li> </ol>"},{"location":"#example-output","title":"Example output","text":"<p>This is a single Element context in TSV format from a K. pneumoniae genome, supplied from a GFA and BED file. You can see that the Element (<code>0db94675-30ef-4b28-a212-f26cbad7409e</code>) contains one CDS, one promoter and is of the IS1380 family. On the same strand downstream is one CDS, annotated as a CTX-M-15 gene, known to confer ESBL resistance. As the Element contains a promoter and is on the same strand downstream, and in close proximity (48bp), we predict this gene is being upregulated.</p> Genome Feature Type Contig Start End Strand Partial Element Element_distance Element_location Element_strand Element_effect Percent_identity Percent_coverage Name Family Group Synonyms Origin IR DR ERR4920392 KNDCPA_05188 CDS 65 834 1710 -1 FALSE 0db94675-30ef-4b28-a212-f26cbad7409e 48bp downstream same strand upregulated - - extended-spectrum class A beta-lactamase CTX-M-15 - - - - - - ERR4920392 0db94675-30ef-4b28-a212-f26cbad7409e mobile_element 65 1758 2157 -1 TRUE 0db94675-30ef-4b28-a212-f26cbad7409e - - - - 100 24.0942029 ISEc9 IS1380 None Escherichia coli 13/22 NA ERR4920392 KNDCPA_05189 CDS 65 1862 1985 -1 FALSE 0db94675-30ef-4b28-a212-f26cbad7409e - inside same strand - - - MobQ family relaxase - - - - - - ERR4920392 0db94675-30ef-4b28-a212-f26cbad7409e_promoter_1 regulatory 65 2053 2083 -1 FALSE 0db94675-30ef-4b28-a212-f26cbad7409e - inside - - - - - - - - - - -"},{"location":"#pan","title":"Pan \ud83e\udd98","text":"<p><code>eris pan</code> quantifies the effect of IS-mediated events in pan-genome graphs.</p> <p>Coming soon!</p>"},{"location":"#map","title":"Map \ud83d\uddfa\ufe0f","text":"<p>Re-implementation of ISMapper, with reference-based and reference-free options.</p> <p>Coming soon!</p> <p></p>"},{"location":"reference/eris/","title":"eris","text":"<p>Top-level module, including resource and optional dependency management.</p>"},{"location":"reference/eris/#eris.DependencyWarning","title":"<code>DependencyWarning</code>","text":"<p>               Bases: <code>ErisWarning</code></p> <p>Custom warning class for missing optional dependencies.</p> Source code in <code>eris/__init__.py</code> <pre><code>class DependencyWarning(ErisWarning):\n    \"\"\"Custom warning class for missing optional dependencies.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/eris/#eris.ErisWarning","title":"<code>ErisWarning</code>","text":"<p>               Bases: <code>Warning</code></p> <p>A warning class for this package, making it easy to silence all our warning messages should you wish to. Consult the <code>python.warnings</code> module documentation for more details.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import warnings\n&gt;&gt;&gt; from eris import ErisWarning\n... warnings.simplefilter('ignore', ErisWarning)\n</code></pre> Source code in <code>eris/__init__.py</code> <pre><code>class ErisWarning(Warning):\n    \"\"\"\n    A warning class for this package, making it easy to silence all our warning messages should you wish to.\n    Consult the `python.warnings` module documentation for more details.\n\n    Examples:\n        &gt;&gt;&gt; import warnings\n        &gt;&gt;&gt; from eris import ErisWarning\n        ... warnings.simplefilter('ignore', ErisWarning)\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/eris/#eris.Resources","title":"<code>Resources</code>","text":"<p>Holds global resources for this package which are generated on demand.</p> <p>Attributes:</p> Name Type Description <code>package</code> <code>str</code> <p>Name of the package</p> <code>optional_packages</code> <code>set[str]</code> <p>Set of optional packages to check for</p> Source code in <code>eris/__init__.py</code> <pre><code>class Resources:\n    \"\"\"\n    Holds global resources for this package which are generated on demand.\n\n    Attributes:\n        package: Name of the package\n        optional_packages: Set of optional packages to check for\n    \"\"\"\n    def __init__(self, *optional_packages: str):\n        \"\"\"\n        Parameters:\n            optional_packages: Optional packages to check for, e.g. 'numpy', 'pandas'\n        \"\"\"\n        self.package: str = Path(__file__).parent.name\n        self.optional_packages: set[str] = set(filter(self._check_module, optional_packages))\n        self._data: 'Traversible' = None  # Generated on demand\n        self._metadata: 'PackageMetadata' = None  # Generated on demand\n        self._available_cpus: int = None  # Generated on demand\n        self._rng: 'Random' = None  # Generated on demand\n        self._pool: 'Executor' = None  # Generated on demand\n\n    @property\n    def data(self) -&gt; 'Traversable':\n        \"\"\"Path to the package data\"\"\"\n        if self._data is None:\n            from importlib.resources import files\n            self._data = files(self.package) / 'data'\n        return self._data\n\n    @property\n    def metadata(self) -&gt; 'PackageMetadata':\n        \"\"\"Package metadata\"\"\"\n        if self._metadata is None:\n            from importlib.metadata import metadata\n            self._metadata = metadata(self.package)\n        return self._metadata\n\n    @property\n    def rng(self) -&gt; 'Random':\n        \"\"\"A random number generator instance, can be reused\"\"\"\n        if self._rng is None:\n            from random import Random\n            self._rng = Random()\n        return self._rng\n\n    @property\n    def available_cpus(self) -&gt; int:\n        \"\"\"Number of available CPUs\"\"\"\n        if self._available_cpus is None:\n            try:\n                from os import process_cpu_count as cpu_count\n            except ImportError:\n                from os import cpu_count\n            self._available_cpus = cpu_count()\n        return self._available_cpus\n\n    @property\n    def pool(self) -&gt; 'Executor':\n        \"\"\"A concurrent.futures.Executor instance\"\"\"\n        if self._pool is None:\n            from concurrent.futures import ThreadPoolExecutor\n            self._pool = ThreadPoolExecutor(min(32, self.available_cpus + 4))\n        return self._pool\n\n    @staticmethod\n    def _check_module(module_name: str) -&gt; bool:\n        \"\"\"Checks if a module can be imported.\n\n        Args:\n            module_name (str): The name of the module to check.\n\n        Returns:\n            bool: True if the module can be imported, False otherwise.\n        \"\"\"\n        try:\n            import_module(module_name)\n            return True\n        except ImportError:\n            return False\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if self._pool is not None:\n            self._pool.shutdown(wait=False, cancel_futures=True)\n\n    def __del__(self):\n        if self._pool is not None:\n            self._pool.shutdown(wait=False, cancel_futures=True)\n</code></pre>"},{"location":"reference/eris/#eris.Resources.available_cpus","title":"<code>available_cpus</code>  <code>property</code>","text":"<p>Number of available CPUs</p>"},{"location":"reference/eris/#eris.Resources.data","title":"<code>data</code>  <code>property</code>","text":"<p>Path to the package data</p>"},{"location":"reference/eris/#eris.Resources.metadata","title":"<code>metadata</code>  <code>property</code>","text":"<p>Package metadata</p>"},{"location":"reference/eris/#eris.Resources.pool","title":"<code>pool</code>  <code>property</code>","text":"<p>A concurrent.futures.Executor instance</p>"},{"location":"reference/eris/#eris.Resources.rng","title":"<code>rng</code>  <code>property</code>","text":"<p>A random number generator instance, can be reused</p>"},{"location":"reference/eris/#eris.Resources.__init__","title":"<code>__init__(*optional_packages)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>optional_packages</code> <code>str</code> <p>Optional packages to check for, e.g. 'numpy', 'pandas'</p> <code>()</code> Source code in <code>eris/__init__.py</code> <pre><code>def __init__(self, *optional_packages: str):\n    \"\"\"\n    Parameters:\n        optional_packages: Optional packages to check for, e.g. 'numpy', 'pandas'\n    \"\"\"\n    self.package: str = Path(__file__).parent.name\n    self.optional_packages: set[str] = set(filter(self._check_module, optional_packages))\n    self._data: 'Traversible' = None  # Generated on demand\n    self._metadata: 'PackageMetadata' = None  # Generated on demand\n    self._available_cpus: int = None  # Generated on demand\n    self._rng: 'Random' = None  # Generated on demand\n    self._pool: 'Executor' = None  # Generated on demand\n</code></pre>"},{"location":"reference/eris/#eris.require","title":"<code>require(*packages)</code>","text":"<p>A decorator to check for required optional packages before executing a function.</p> <p>Parameters:</p> Name Type Description Default <code>*packages</code> <code>str</code> <p>Variable number of package names (strings) that are required.</p> <code>()</code> <p>Returns:</p> Type Description <code>Callable</code> <p>A decorator that wraps the function. If any required packages are missing,</p> <code>Callable</code> <p>it issues a DependencyWarning and returns None. Otherwise, it executes</p> <code>Callable</code> <p>the original function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from eris import require\n... @require('numpy')\n... def some_numpy_func():\n... ...\n</code></pre> Source code in <code>eris/__init__.py</code> <pre><code>def require(*packages: str) -&gt; Callable:\n    \"\"\"\n    A decorator to check for required optional packages before executing a function.\n\n    Args:\n        *packages: Variable number of package names (strings) that are required.\n\n    Returns:\n        A decorator that wraps the function. If any required packages are missing,\n        it issues a DependencyWarning and returns None. Otherwise, it executes\n        the original function.\n\n    Examples:\n        &gt;&gt;&gt; from eris import require\n        ... @require('numpy')\n        ... def some_numpy_func():\n        ... ...\n    \"\"\"\n    def decorator(func: Callable) -&gt; Callable:\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            if missing_deps := [dep for dep in packages if dep not in RESOURCES.optional_packages]:\n                warn(\n                    f\"Function '{func.__name__}' requires the following missing dependencies: \"\n                    f\"{', '.join(missing_deps)}. Skipping execution.\",\n                    DependencyWarning\n                )\n                return None\n            return func(*args, **kwargs)\n        return wrapper\n    return decorator\n</code></pre>"},{"location":"reference/eris/alignment/","title":"eris.alignment","text":"<p>Module for parsing, viewing and managing sequence alignments.</p>"},{"location":"reference/eris/alignment/#eris.alignment.Alignment","title":"<code>Alignment</code>","text":"<p>               Bases: <code>HasLocation</code></p> <p>Class representing an alignment between a query sequence and target sequence.</p> <p>Attributes:</p> Name Type Description <code>query</code> <code>str</code> <p>Query sequence name</p> <code>query_length</code> <code>int</code> <p>Query sequence length</p> <code>query_start</code> <code>int</code> <p>Query start coordinate (0-based)</p> <code>query_end</code> <code>int</code> <p>Query end coordinate (0-based)</p> <code>target</code> <code>str</code> <p>Target sequence name</p> <code>target_length</code> <code>int</code> <p>Target sequence length</p> <code>length</code> <code>int</code> <p>Number of residues in the alignment including gaps</p> <code>cigar</code> <code>str</code> <p>CIGAR string</p> <code>score</code> <code>float</code> <p>Alignment score</p> <code>E</code> <code>float</code> <p>Alignment entropy</p> <code>n_matches</code> <code>int</code> <p>Number of matching residues in the alignment</p> <code>quality</code> <code>int</code> <p>Mapping quality (0-255 with 255 for missing)</p> <code>tags</code> <code>dict[str, Union[str, int, float]]</code> <p>{tag: value} pairs</p> <code>identity</code> <code>float</code> <p>Percentage of matching residues</p> <code>query_coverage</code> <code>float</code> <p>Percentage of query sequence covered by the alignment</p> <code>target_coverage</code> <code>float</code> <p>Percentage of target sequence covered by the alignment</p> <code>aligned_seqs</code> <code>tuple[Seq, Seq]</code> <p>Tuple of aligned sequences</p> Source code in <code>eris/alignment.py</code> <pre><code>class Alignment(HasLocation):\n    \"\"\"\n    Class representing an alignment between a query sequence and target sequence.\n\n    Attributes:\n        query: Query sequence name\n        query_length: Query sequence length\n        query_start: Query start coordinate (0-based)\n        query_end: Query end coordinate (0-based)\n        target: Target sequence name\n        target_length: Target sequence length\n        length: Number of residues in the alignment including gaps\n        cigar: CIGAR string\n        score: Alignment score\n        E: Alignment entropy\n        n_matches: Number of matching residues in the alignment\n        quality: Mapping quality (0-255 with 255 for missing)\n        tags: {tag: value} pairs\n        identity: Percentage of matching residues\n        query_coverage: Percentage of query sequence covered by the alignment\n        target_coverage: Percentage of target sequence covered by the alignment\n        aligned_seqs: Tuple of aligned sequences\n    \"\"\"\n\n    def __init__(self, query: str, query_start: int, query_end: int, target: str, location: Location,\n                 query_length: int = 0, target_length: int = 0, length: int = 0, cigar: str = None,\n                 n_matches: int = 0, quality: int = 0, tags: dict[str, Union[str, int, float]] = None, score: float = 0,\n                 E: float = 0, identity: float = 0,  query_coverage: float = 0, target_coverage: float = 0,\n                 aligned_seqs: tuple[Seq, Seq] = None):\n        super().__init__(location)\n        self.query: str = query  # Query sequence name\n        self.query_length: int = query_length  # Query sequence length\n        self.query_start: int = query_start  # Query start coordinate (0-based)\n        self.query_end: int = query_end  # Query end coordinate (0-based)\n        self.target: str = target  # Target sequence name\n        self.target_length: int = target_length  # Target sequence length\n        self.length: int = length  # Number of residues in the alignment including gaps\n        self.cigar: str = cigar\n        self.score: float = score\n        self.E: float = E\n        self.n_matches: int = n_matches  # Number of matching residues in the alignment\n        self.quality: int = quality  # Mapping quality (0-255 with 255 for missing)\n        self.tags: dict[str, Union[str, int, float]] = tags or {}  # {tag: value} pairs)\n        self.identity: float = identity\n        self.query_coverage: float = query_coverage\n        self.target_coverage: float = target_coverage\n        self.aligned_seqs: tuple[Seq, Seq] = aligned_seqs\n\n    def __repr__(self):\n        return f'{self.query}:{self.query_start}-{self.query_end} {self.target}:{self.location}'\n\n    def __len__(self):\n        return self.length\n\n    @classmethod\n    def from_paf(cls, paf_line: str):\n        \"\"\"\n        Parse a line in PAF format and return an Alignment object.\n\n        Parameters:\n            paf_line: A text string representing a single alignment\n        \"\"\"\n        if len(paf_line := paf_line.strip().split('\\t')) &lt; 12:\n            raise AlignmentError(f\"PAF Line has &lt; 12 columns: {paf_line}\")\n        try:\n            self = Alignment(  # Parse standard fields\n                query=paf_line[0], query_length=int(paf_line[1]), query_start=int(paf_line[2]),\n                query_end=int(paf_line[3]), target=paf_line[5],\n                location=Location(int(paf_line[7]), int(paf_line[8]), 1 if paf_line[4] == '+' else -1),\n                target_length=int(paf_line[6]), n_matches=int(paf_line[9]), length=int(paf_line[10]),\n                quality=int(paf_line[11]), tags={\n                    (x := t.split(\":\", 2))[0]:\n                        int(x[2]) if x[1] == \"i\" else float(x[2]) if x[1] == \"f\" else x[2] for\n                    t in paf_line[12:]\n                }\n            )\n            self.identity = (self.n_matches / self.length) * 100\n            self.query_coverage = (self.length / self.query_length) * 100  # TODO: Exclude gaps from these counts\n            self.target_coverage = (self.length / self.target_length) * 100  # TODO: Exclude gaps from these counts\n            if 'cg' in self.tags:  # Add cigar to attributes\n                self.cigar = self.tags.pop('cg')\n            if 'AS' in self.tags:  # Add alignment score to attributes\n                self.score = self.tags.pop('AS')\n            self.location.parent_id = self.target\n\n            is_partial_at_query_start = self.query_start &gt; 0\n            is_partial_at_query_end = self.query_end &lt; self.query_length\n\n            if self.location.strand == 1:\n                self.location.partial_start = is_partial_at_query_start\n                self.location.partial_end = is_partial_at_query_end\n            else:\n                self.location.partial_start = is_partial_at_query_end\n                self.location.partial_end = is_partial_at_query_start\n\n            return self\n        except Exception as e:\n            raise AlignmentError(f\"Error parsing PAF line: {paf_line}: {e}\")\n\n    def get_aligned_seqs(self, query: Seq = None, target: Seq = None, gap_character: str = '-') -&gt; tuple[Seq, Seq]:\n        \"\"\"\n        Calculates the aligned sequences from the query and target sequences using the cigar.\n        Will also set the ``aligned_seqs`` attribute.\n\n        :param query: The query sequence\n        :param target: The target sequence\n        :param gap_character: The character to use to represent gaps\n        :return: A tuple of aligned sequences\n        \"\"\"\n        if not self.aligned_seqs:\n            assert query, AlignmentError('Need a query sequence to compute traceback')\n            assert target, AlignmentError('Need a target sequence to compute traceback')\n            assert len(query) == self.query_length, AlignmentError('Query length does not match alignment length')\n            assert len(target) == self.target_length, AlignmentError('Target length does not match alignment length')\n            query_trimmed = str(query[self.query_start:self.query_end])\n            target_trimmed = str(target[self.location.start:self.location.end])\n            query_traceback, target_traceback = [], []\n            query_position, target_position = 0, 0\n            for operation, n in parse_cigar(self.cigar):\n                if operation in _QUERY_CONSUMING_OPERATIONS:\n                    query_traceback.append(query_trimmed[query_position:query_position + n])\n                    query_position += n\n                else:\n                    query_traceback.append(gap_character * n)\n                if operation in _TARGET_CONSUMING_OPERATIONS:\n                    target_traceback.append(target_trimmed[target_position:target_position + n])\n                    target_position += n\n                else:\n                    target_traceback.append(gap_character * n)\n\n            self.aligned_seqs = (Seq(''.join(query_traceback), query.alphabet), Seq(''.join(target_traceback), target.alphabet))\n        return self.aligned_seqs\n\n    def print(self, wrap: int = 70):\n        assert self.aligned_seqs, AlignmentError(f'Aligned sequences have not been computed for {self}')\n        query, target = self.aligned_seqs\n        matches = ''.join('|' if x == y else '.' for x, y in zip(query, target))\n        rjust = len(str(max(self.query_start, self.location.start)))\n        for i in range(0, self.length, wrap):\n            print(f\"target {self.location.start + i:&gt;{rjust}} {target[i:i + wrap]}\\n\"\n                  f\"       {i:&gt;{rjust}} {matches[i:i + wrap]}\\n\"\n                  f\"query  {self.query_start + i:&gt;{rjust}} {query[i:i + wrap]}\")\n\n    def as_feature(self, kind: str = 'misc_feature') -&gt; Feature:\n        return Feature(\n            location=self.location, kind=kind, qualifiers=[\n                Qualifier('name', self.query),\n                Qualifier('query_start', self.query_start),\n                Qualifier('query_end', self.query_end),\n                Qualifier('query_length', self.query_length),\n                Qualifier('query_coverage', self.query_coverage),\n                Qualifier('target_length', self.target_length),\n                Qualifier('target_coverage', self.target_coverage),\n                Qualifier('identity', self.identity),\n                Qualifier('length', self.length),\n                Qualifier('cigar', self.cigar),\n                Qualifier('n_matches', self.n_matches),\n                Qualifier('quality', self.quality),\n                Qualifier('score', self.score),\n                Qualifier('E', self.E)\n            ]\n        )\n</code></pre>"},{"location":"reference/eris/alignment/#eris.alignment.Alignment.from_paf","title":"<code>from_paf(paf_line)</code>  <code>classmethod</code>","text":"<p>Parse a line in PAF format and return an Alignment object.</p> <p>Parameters:</p> Name Type Description Default <code>paf_line</code> <code>str</code> <p>A text string representing a single alignment</p> required Source code in <code>eris/alignment.py</code> <pre><code>@classmethod\ndef from_paf(cls, paf_line: str):\n    \"\"\"\n    Parse a line in PAF format and return an Alignment object.\n\n    Parameters:\n        paf_line: A text string representing a single alignment\n    \"\"\"\n    if len(paf_line := paf_line.strip().split('\\t')) &lt; 12:\n        raise AlignmentError(f\"PAF Line has &lt; 12 columns: {paf_line}\")\n    try:\n        self = Alignment(  # Parse standard fields\n            query=paf_line[0], query_length=int(paf_line[1]), query_start=int(paf_line[2]),\n            query_end=int(paf_line[3]), target=paf_line[5],\n            location=Location(int(paf_line[7]), int(paf_line[8]), 1 if paf_line[4] == '+' else -1),\n            target_length=int(paf_line[6]), n_matches=int(paf_line[9]), length=int(paf_line[10]),\n            quality=int(paf_line[11]), tags={\n                (x := t.split(\":\", 2))[0]:\n                    int(x[2]) if x[1] == \"i\" else float(x[2]) if x[1] == \"f\" else x[2] for\n                t in paf_line[12:]\n            }\n        )\n        self.identity = (self.n_matches / self.length) * 100\n        self.query_coverage = (self.length / self.query_length) * 100  # TODO: Exclude gaps from these counts\n        self.target_coverage = (self.length / self.target_length) * 100  # TODO: Exclude gaps from these counts\n        if 'cg' in self.tags:  # Add cigar to attributes\n            self.cigar = self.tags.pop('cg')\n        if 'AS' in self.tags:  # Add alignment score to attributes\n            self.score = self.tags.pop('AS')\n        self.location.parent_id = self.target\n\n        is_partial_at_query_start = self.query_start &gt; 0\n        is_partial_at_query_end = self.query_end &lt; self.query_length\n\n        if self.location.strand == 1:\n            self.location.partial_start = is_partial_at_query_start\n            self.location.partial_end = is_partial_at_query_end\n        else:\n            self.location.partial_start = is_partial_at_query_end\n            self.location.partial_end = is_partial_at_query_start\n\n        return self\n    except Exception as e:\n        raise AlignmentError(f\"Error parsing PAF line: {paf_line}: {e}\")\n</code></pre>"},{"location":"reference/eris/alignment/#eris.alignment.Alignment.get_aligned_seqs","title":"<code>get_aligned_seqs(query=None, target=None, gap_character='-')</code>","text":"<p>Calculates the aligned sequences from the query and target sequences using the cigar. Will also set the <code>aligned_seqs</code> attribute.</p> <p>:param query: The query sequence :param target: The target sequence :param gap_character: The character to use to represent gaps :return: A tuple of aligned sequences</p> Source code in <code>eris/alignment.py</code> <pre><code>def get_aligned_seqs(self, query: Seq = None, target: Seq = None, gap_character: str = '-') -&gt; tuple[Seq, Seq]:\n    \"\"\"\n    Calculates the aligned sequences from the query and target sequences using the cigar.\n    Will also set the ``aligned_seqs`` attribute.\n\n    :param query: The query sequence\n    :param target: The target sequence\n    :param gap_character: The character to use to represent gaps\n    :return: A tuple of aligned sequences\n    \"\"\"\n    if not self.aligned_seqs:\n        assert query, AlignmentError('Need a query sequence to compute traceback')\n        assert target, AlignmentError('Need a target sequence to compute traceback')\n        assert len(query) == self.query_length, AlignmentError('Query length does not match alignment length')\n        assert len(target) == self.target_length, AlignmentError('Target length does not match alignment length')\n        query_trimmed = str(query[self.query_start:self.query_end])\n        target_trimmed = str(target[self.location.start:self.location.end])\n        query_traceback, target_traceback = [], []\n        query_position, target_position = 0, 0\n        for operation, n in parse_cigar(self.cigar):\n            if operation in _QUERY_CONSUMING_OPERATIONS:\n                query_traceback.append(query_trimmed[query_position:query_position + n])\n                query_position += n\n            else:\n                query_traceback.append(gap_character * n)\n            if operation in _TARGET_CONSUMING_OPERATIONS:\n                target_traceback.append(target_trimmed[target_position:target_position + n])\n                target_position += n\n            else:\n                target_traceback.append(gap_character * n)\n\n        self.aligned_seqs = (Seq(''.join(query_traceback), query.alphabet), Seq(''.join(target_traceback), target.alphabet))\n    return self.aligned_seqs\n</code></pre>"},{"location":"reference/eris/alignment/#eris.alignment.cull","title":"<code>cull(keep, alignments, max_overlap_fraction=0.1)</code>","text":"<p>Filters alignments by excluding those that overlap a reference alignment beyond a specified fraction.</p> <p>This function takes a reference alignment and iterates through a collection of alignments, yielding only those alignments whose target does not match the target of the reference alignment, or whose overlap ratio with the reference alignment (calculated as the overlap divided by the length of the alignment) is less than a provided maximum overlap fraction.</p> <p>Parameters:</p> Name Type Description Default <code>keep</code> <code>Alignment</code> <p>The reference alignment used for comparison.</p> required <code>alignments</code> <code>Iterable[Alignment]</code> <p>A collection of alignments to be filtered.</p> required <code>max_overlap_fraction</code> <code>float</code> <p>The maximum allowed fraction of overlap between the reference alignment and any given alignment. Defaults to 0.1.</p> <code>0.1</code> <p>Yields:</p> Type Description <code>Alignment</code> <p>Generator[Alignment, None, None]: A generator that yields alignments meeting the specified criteria.</p> Source code in <code>eris/alignment.py</code> <pre><code>def cull(keep: Alignment, alignments: Iterable[Alignment], max_overlap_fraction: float = 0.1\n         ) -&gt; Generator[Alignment, None, None]:\n    \"\"\"\n    Filters alignments by excluding those that overlap a reference alignment beyond a specified fraction.\n\n    This function takes a reference alignment and iterates through a collection of\n    alignments, yielding only those alignments whose target does not match the\n    target of the reference alignment, or whose overlap ratio with the reference\n    alignment (calculated as the overlap divided by the length of the alignment)\n    is less than a provided maximum overlap fraction.\n\n    Args:\n        keep (Alignment): The reference alignment used for comparison.\n        alignments (Iterable[Alignment]): A collection of alignments to be filtered.\n        max_overlap_fraction (float): The maximum allowed fraction of overlap\n            between the reference alignment and any given alignment. Defaults to 0.1.\n\n    Yields:\n        Generator[Alignment, None, None]: A generator that yields alignments\n            meeting the specified criteria.\n    \"\"\"\n    for a in alignments:\n        if a.target != keep.target or (a.overlap(keep) / a.length) &lt; max_overlap_fraction:\n            yield a\n</code></pre>"},{"location":"reference/eris/alignment/#eris.alignment.cull_all","title":"<code>cull_all(alignments, key='n_matches', reverse_sort=True)</code>","text":"<p>Sort and filter a collection of alignments based on a specified key. The function sorts alignments by the given key and iteratively compares the alignments, keeping those that meet certain criteria and removes others.</p> <p>Parameters:</p> Name Type Description Default <code>alignments</code> <code>Iterable[Alignment]</code> <p>A collection of Alignment objects to be processed.</p> required <code>key</code> <code>str</code> <p>The attribute name used for sorting alignments. Defaults to 'n_matches'.</p> <code>'n_matches'</code> <code>reverse_sort</code> <code>bool</code> <p>If True, sort alignments in descending order using the specified key. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>list[Alignment]</code> <p>list[Alignment]: A filtered and sorted list of alignments, meeting specified criteria.</p> Source code in <code>eris/alignment.py</code> <pre><code>def cull_all(alignments: Iterable[Alignment], key='n_matches', reverse_sort: bool = True) -&gt; list[Alignment]:\n    \"\"\"\n    Sort and filter a collection of alignments based on a specified key. The function sorts\n    alignments by the given key and iteratively compares the alignments, keeping those that\n    meet certain criteria and removes others.\n\n    Arguments:\n        alignments (Iterable[Alignment]): A collection of Alignment objects to be processed.\n        key (str): The attribute name used for sorting alignments. Defaults to 'n_matches'.\n        reverse_sort (bool): If True, sort alignments in descending order using the specified\n            key. Defaults to True.\n\n    Returns:\n        list[Alignment]: A filtered and sorted list of alignments, meeting specified criteria.\n    \"\"\"\n    kept_alignments = []\n    sorted_alignments = sorted(alignments, key=attrgetter(key), reverse=reverse_sort)\n    while sorted_alignments:\n        kept_alignments.append(sorted_alignments.pop(0))\n        sorted_alignments = list(cull(kept_alignments[-1], sorted_alignments))\n    return kept_alignments\n</code></pre>"},{"location":"reference/eris/alignment/#eris.alignment.parse_cigar","title":"<code>parse_cigar(cigar)</code>","text":"<p>Parses the cigar with a regular expression :return: A Generator of tuples containing the operation symbol and span</p> Source code in <code>eris/alignment.py</code> <pre><code>def parse_cigar(cigar: str) -&gt; Generator[tuple[Literal['M', 'I', 'D', 'N', 'S', 'H', 'P', '=', 'X'], int], None, None]:\n    \"\"\"\n    Parses the cigar with a regular expression\n    :return: A Generator of tuples containing the operation symbol and span\n    \"\"\"\n    if cigar:\n        for match in _CIGAR_OPERATIONS.finditer(cigar):\n            if not match:\n                raise AlignmentError(f'Could not parse cigar: {cigar}')\n            yield match['operation'], int(match['n'])\n</code></pre>"},{"location":"reference/eris/alphabet/","title":"eris.alphabet","text":"<p>Module to handle biological sequence alphabets. Mostly redundant, but kept for random sequence generation and encoding.</p>"},{"location":"reference/eris/alphabet/#eris.alphabet.Alphabet","title":"<code>Alphabet</code>","text":"<p>A class to represent an alphabet of symbols.</p> Source code in <code>eris/alphabet.py</code> <pre><code>class Alphabet:\n    \"\"\"\n    A class to represent an alphabet of symbols.\n    \"\"\"\n    def __init__(self, symbols: str):\n        self._symbols = symbols\n        self._set: frozenset[str] = frozenset(symbols)\n        if len(self._set) &lt; len(self._symbols):\n            raise AlphabetError(f'Alphabet symbols \"{symbols}\" are not unique')\n\n    def __len__(self):\n        return len(self._symbols)\n\n    def __repr__(self):\n        return self._symbols\n\n    def __hash__(self):\n        return hash(self._set)\n\n    def __eq__(self, other):\n        if isinstance(other, Alphabet):\n            return self._symbols == other._symbols\n        return False\n\n    def __contains__(self, item: str):\n        return set(item) &lt;= self._set\n\n    def __iter__(self):\n        return iter(self._symbols)\n\n    def __getitem__(self, item):\n        return self._symbols[item]\n</code></pre>"},{"location":"reference/eris/cli/","title":"eris.cli","text":"<p>Module for managing the CLI layer on top of the API; also contains the CLI entry point under <code>main()</code>.</p>"},{"location":"reference/eris/cli/#eris.cli.ProgressBar","title":"<code>ProgressBar</code>","text":"<p>A CLI progress bar that wraps an iterable and calls a function for each item.</p> <p>This class acts as an iterator, yielding results from the callable while printing a dynamic progress bar to stderr.</p> <p>Parameters:</p> Name Type Description Default <code>iterable</code> <code>Iterable</code> <p>An iterable of items to process.</p> required <code>callable</code> <code>Callable</code> <p>A function to call for each item from the iterable.</p> required <code>desc</code> <code>str</code> <p>A description to display before the progress bar.</p> <code>'Processing items'</code> <code>bar_length</code> <code>int</code> <p>The character length of the progress bar.</p> <code>40</code> <code>bar_character</code> <code>str</code> <p>The character used to fill the progress bar.</p> <code>'\u2588'</code> <code>silence</code> <code>bool</code> <p>Silence the bar</p> <code>False</code> Source code in <code>eris/cli.py</code> <pre><code>class ProgressBar:\n    \"\"\"\n    A CLI progress bar that wraps an iterable and calls a function for each item.\n\n    This class acts as an iterator, yielding results from the callable while\n    printing a dynamic progress bar to stderr.\n\n    Args:\n        iterable (Iterable): An iterable of items to process.\n        callable (Callable): A function to call for each item from the iterable.\n        desc (str): A description to display before the progress bar.\n        bar_length (int): The character length of the progress bar.\n        bar_character (str): The character used to fill the progress bar.\n        silence (bool): Silence the bar\n    \"\"\"\n    def __init__(self, iterable: Iterable, callable: Callable[[Any], Any], desc: str = \"Processing items\",\n                 bar_length: int = 40, bar_character: str = '\u2588', silence: bool = False):\n        # Eagerly consume the iterable to get a total count for the progress bar.\n        assert len(bar_character) == 1, \"Bar character must be a single character\"\n        self.items = list(iterable)\n        self.total = len(self.items)\n        self.callable = callable\n        self.desc = desc\n        self.bar_length = bar_length\n        self.bar_character = bar_character\n        self.silence = silence\n        self._iterator: Iterable = None\n        self.start_time: float = None\n        self._processed_count: int = 0\n\n    def _format_time(self, seconds: float) -&gt; str:\n        \"\"\"Formats seconds into a HH:MM:SS string.\"\"\"\n        if not isinstance(seconds, (int, float)) or seconds &lt; 0:\n            return \"00:00:00\"\n        m, s = divmod(seconds, 60)\n        h, m = divmod(m, 60)\n        return f\"{int(h):02d}:{int(m):02d}:{int(s):02d}\"\n\n    def __iter__(self):\n        self._iterator = iter(self.items)\n        self.start_time = time.time()\n        self._processed_count = 0\n        if not self.silence:\n            self._update_progress()  # Display the initial (0%) bar\n        return self\n\n    def __next__(self):\n        # The for-loop protocol will handle the StopIteration from next()\n        item = next(self._iterator)\n\n        # The core of the wrapper: call the provided callable for one item.\n        result = self.callable(item)\n        self._processed_count += 1\n        if not self.silence:\n            self._update_progress()\n        return result\n\n    def _update_progress(self):\n        \"\"\"Calculates and prints the progress bar to stderr.\"\"\"\n        if self.total == 0:\n            return\n\n        percent_complete = self._processed_count / self.total\n        filled_length = int(self.bar_length * percent_complete)\n        bar = self.bar_character * filled_length + '-' * (self.bar_length - filled_length)\n\n        elapsed_time = time.time() - self.start_time\n\n        # Calculate Estimated Time of Arrival (ETA)\n        if self._processed_count &gt; 0:\n            avg_time_per_item = elapsed_time / self._processed_count\n            remaining_items = self.total - self._processed_count\n            eta = avg_time_per_item * remaining_items\n        else:\n            eta = float('inf')\n\n        # Format time strings\n        elapsed_str = self._format_time(elapsed_time)\n        eta_str = self._format_time(eta) if eta != float('inf') else '??:??:??'\n\n        # Use carriage return '\\r' to stay on the same line\n        progress_line = (f'\\r{self.desc}: {int(percent_complete * 100):&gt;3}%|{bar}| '\n                         f'{self._processed_count}/{self.total} '\n                         f'[{elapsed_str}&lt;{eta_str}]')\n\n        stderr.write(progress_line)\n\n        # When the loop is finished, print a newline to move to the next line\n        if self._processed_count == self.total:\n            stderr.write('\\n')\n\n        stderr.flush()\n\n    def __len__(self):\n        return self.total\n</code></pre>"},{"location":"reference/eris/cli/#eris.cli.ResultWriter","title":"<code>ResultWriter</code>","text":"<p>A class to handle the writing of results to multiple types of files; to be used with the CLI.</p> Source code in <code>eris/cli.py</code> <pre><code>class ResultWriter:\n    \"\"\"\n    A class to handle the writing of results to multiple types of files; to be used with the CLI.\n    \"\"\"\n    def __init__(self, *outputs: tuple[str, Union[str, Path, IO]], suffix: str = _SUFFIX,\n                 no_tsv_header: bool = False, tsv_header: str = '#', pool: Executor = None):\n        \"\"\"\n        :param suffix: Suffix to append to output filenames\n        :param no_tsv_header: Suppress header in TSV output (default: False)\n        \"\"\"\n        self._files = {}\n        self._handles = {}\n        self.suffix: str = suffix\n        self.tsv_header: str = tsv_header\n        self._header_written: bool = no_tsv_header\n        for format, argument in outputs:\n            if argument is not None:\n                if argument in {'-', 'stdout'}:\n                    self._handles[format] = stdout\n                    # self._handle_locks[format] = Lock()\n                elif isinstance(argument, str):\n                    self._files[format] = Path(argument)\n                elif isinstance(argument, Path):\n                    self._files[format] = argument\n                elif isinstance(argument, IOBase):\n                    self._handles[format] = argument\n                    # self._handle_locks[format] = Lock()\n                else:\n                    raise TypeError(f\"{format=} {argument=} must be a string, Path or IO, not {type(argument)}\")\n\n        if not self._files and not self._handles:\n            raise ValueError(\"No outputs specified\")\n\n    def __len__(self):\n        return len(self._files) + len(self._handles)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.close()\n        # Wait for all writes to finish before exiting context\n        # self.pool.shutdown(wait=True)\n\n    def __del__(self):\n        self.close()\n        # Avoid __del__ for resource management; __exit__ is preferred. If it is called, try to clean up.\n        # self.pool.shutdown(wait=False)\n\n    def close(self):\n        \"\"\"Close the handles that aren't stdout or stderr\"\"\"\n        for handle in self._handles.values():\n            if handle.name not in {'&lt;stdout&gt;', '&lt;stderr&gt;'}:  # These handles cannot be opened or closed\n                handle.close()\n\n    def _write(self, fmt: str, out: Union[str, Path, IO], result, open_mode: str) -&gt; int:\n        if fmt in self._handles:\n            # Acquire lock for the specific handle to ensure thread-safe writing\n            # with self._handle_locks[out]:\n            #     # Logic for non-repeating TSV header\n            #     if fmt == 'tsv' and not self._header_written:\n            #         out.write(self.tsv_header)\n            #         self._header_written = True\n            #     out.write(format(result, fmt))\n            # Logic for non-repeating TSV header\n            if fmt == 'tsv' and not self._header_written:\n                out.write(self.tsv_header)\n                self._header_written = True\n            return out.write(format(result, fmt))\n        else:  # This logic is for self.files\n            with open(out / f'{result.genome_id}{self.suffix}.{fmt}', mode=open_mode) as handle:\n                return handle.write(format(result, fmt))\n\n    def write(self, result: Union['Result', None], open_mode: str = 'wt'):\n        \"\"\"\n        Write the typing result to files or file handles\n        :param result: A Result instance or None\n        :param open_mode: The mode to open the files in\n        \"\"\"\n        if result is None:\n            return None\n        # Use the pool to write the result, iterating over the handles and files dictionaries\n        # for fmt, out in chain(self._handles.items(), self._files.items()):\n        #     self.pool.submit(self._write, result, fmt, out, open_mode)\n        for fmt, out in chain(self._handles.items(), self._files.items()):\n            self._write(fmt, out, result, open_mode)\n</code></pre>"},{"location":"reference/eris/cli/#eris.cli.ResultWriter.__init__","title":"<code>__init__(*outputs, suffix=_SUFFIX, no_tsv_header=False, tsv_header='#', pool=None)</code>","text":"<p>:param suffix: Suffix to append to output filenames :param no_tsv_header: Suppress header in TSV output (default: False)</p> Source code in <code>eris/cli.py</code> <pre><code>def __init__(self, *outputs: tuple[str, Union[str, Path, IO]], suffix: str = _SUFFIX,\n             no_tsv_header: bool = False, tsv_header: str = '#', pool: Executor = None):\n    \"\"\"\n    :param suffix: Suffix to append to output filenames\n    :param no_tsv_header: Suppress header in TSV output (default: False)\n    \"\"\"\n    self._files = {}\n    self._handles = {}\n    self.suffix: str = suffix\n    self.tsv_header: str = tsv_header\n    self._header_written: bool = no_tsv_header\n    for format, argument in outputs:\n        if argument is not None:\n            if argument in {'-', 'stdout'}:\n                self._handles[format] = stdout\n                # self._handle_locks[format] = Lock()\n            elif isinstance(argument, str):\n                self._files[format] = Path(argument)\n            elif isinstance(argument, Path):\n                self._files[format] = argument\n            elif isinstance(argument, IOBase):\n                self._handles[format] = argument\n                # self._handle_locks[format] = Lock()\n            else:\n                raise TypeError(f\"{format=} {argument=} must be a string, Path or IO, not {type(argument)}\")\n\n    if not self._files and not self._handles:\n        raise ValueError(\"No outputs specified\")\n</code></pre>"},{"location":"reference/eris/cli/#eris.cli.ResultWriter.close","title":"<code>close()</code>","text":"<p>Close the handles that aren't stdout or stderr</p> Source code in <code>eris/cli.py</code> <pre><code>def close(self):\n    \"\"\"Close the handles that aren't stdout or stderr\"\"\"\n    for handle in self._handles.values():\n        if handle.name not in {'&lt;stdout&gt;', '&lt;stderr&gt;'}:  # These handles cannot be opened or closed\n            handle.close()\n</code></pre>"},{"location":"reference/eris/cli/#eris.cli.ResultWriter.write","title":"<code>write(result, open_mode='wt')</code>","text":"<p>Write the typing result to files or file handles :param result: A Result instance or None :param open_mode: The mode to open the files in</p> Source code in <code>eris/cli.py</code> <pre><code>def write(self, result: Union['Result', None], open_mode: str = 'wt'):\n    \"\"\"\n    Write the typing result to files or file handles\n    :param result: A Result instance or None\n    :param open_mode: The mode to open the files in\n    \"\"\"\n    if result is None:\n        return None\n    # Use the pool to write the result, iterating over the handles and files dictionaries\n    # for fmt, out in chain(self._handles.items(), self._files.items()):\n    #     self.pool.submit(self._write, result, fmt, out, open_mode)\n    for fmt, out in chain(self._handles.items(), self._files.items()):\n        self._write(fmt, out, result, open_mode)\n</code></pre>"},{"location":"reference/eris/db/","title":"eris.db","text":"<p>Module for managing the IS database from ISFinder.</p>"},{"location":"reference/eris/db/#eris.db.Database","title":"<code>Database</code>","text":"<p>A class to manage the ISFinder database, including downloading and parsing the data.</p> <p>Attributes:</p> Name Type Description <code>records</code> <code>dict[str, Record]</code> <p>dict[str, 'Record'] A dictionary of the ISFinder sequences in the database.</p> <code>qualifiers</code> <code>list[str]</code> <p>list[str] A list of metadata qualifiers available for each record.</p> Source code in <code>eris/db.py</code> <pre><code>class Database:\n    \"\"\"\n    A class to manage the ISFinder database, including downloading and parsing the data.\n\n    Attributes:\n        records: dict[str, 'Record'] A dictionary of the ISFinder sequences in the database.\n        qualifiers: list[str] A list of metadata qualifiers available for each record.\n    \"\"\"\n    def __init__(self):\n\n        if not is_non_empty_file(_CSV_PATH):\n            download(_CSV_URL, _CSV_PATH)\n\n        if not is_non_empty_file(_FNA_PATH):\n            download(_FNA_URL, _FNA_PATH)\n\n        self.records: dict[str, 'Record'] = {}\n\n        with open(_CSV_PATH, 'rt') as csv_file, SeqFile(_FNA_PATH, 'fasta') as fna_file:\n            reader = DictReader(csv_file)\n            self.qualifiers: list[str] = reader.fieldnames\n            metadata = {i['Name']: i for i in reader}\n            for record in fna_file:  # type: Record\n                if record_metadata := metadata.get(record.id.partition('_')[0]):\n                    record.qualifiers += [Qualifier(k, v) for k, v in record_metadata.items()]\n                    self.records[record.id] = record\n                # else:\n                #     warn(f'{record} does not have metadata', ErisWarning)\n\n    def __repr__(self):\n        return f'{self.__class__.__name__}({len(self.records)} records)'\n\n    def __len__(self):\n        return len(self.records)\n\n    def __getitem__(self, item):\n        return self.records[item]\n\n    def __iter__(self):\n        return iter(self.records.values())\n</code></pre>"},{"location":"reference/eris/external/","title":"eris.external","text":"<p>Module for managing external programs such as Minimap2.</p>"},{"location":"reference/eris/external/#eris.external.ExternalProgram","title":"<code>ExternalProgram</code>","text":"<p>Base class to handle an external program to be executed in subprocesses</p> Source code in <code>eris/external.py</code> <pre><code>class ExternalProgram:\n    \"\"\"\n    Base class to handle an external program to be executed in subprocesses\n    \"\"\"\n    def __init__(self, program: str):\n        if (binary := next(find_executable_binaries(program))) is None:\n            raise ExternalProgramError(f'Could not find {program}')\n        self._program = program\n        self._binary = binary\n\n    def __repr__(self):\n        return f'{self._program}({self._binary})'\n\n    def __enter__(self):\n        return self\n\n    def _run(self, command, input_: str = None, stdout: bool = True):\n        with Popen(f\"{self._binary} {command}\", shell=True, stderr=PIPE, stdin=PIPE if input_ else DEVNULL,\n                   stdout=PIPE if stdout else DEVNULL, universal_newlines=True) as process:\n            return process.communicate(input=input_)  \n</code></pre>"},{"location":"reference/eris/external/#eris.external.Minimap2","title":"<code>Minimap2</code>","text":"<p>               Bases: <code>ExternalProgram</code></p> <p>An aligner instance using Minimap2. The class can be instantiated with targets which will create a temporary index file, that can be handled safely with context management.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from eris.external import Minimap2\n... from eris.io import Genome\n... with Minimap2(targets=Genome.from_file('tests.fasta')) as aligner:  # Build the index from genome 1\n...     for alignment in aligner(Genome.from_file('test2.gfa')):\n...         print(alignment)\n</code></pre> Source code in <code>eris/external.py</code> <pre><code>class Minimap2(ExternalProgram):\n    \"\"\"\n    An aligner instance using Minimap2. The class can be instantiated with targets which will create a temporary\n    index file, that can be handled safely with context management.\n\n    Examples:\n        &gt;&gt;&gt; from eris.external import Minimap2\n        ... from eris.io import Genome\n        ... with Minimap2(targets=Genome.from_file('tests.fasta')) as aligner:  # Build the index from genome 1\n        ...     for alignment in aligner(Genome.from_file('test2.gfa')):\n        ...         print(alignment)\n    \"\"\"\n    def __init__(self, targets: Union[str, Path, Union[Record, Feature], Iterable[Union[Record, Feature]]] = None,\n                 align_config: Minimap2AlignConfig = None, index_config: Minimap2IndexConfig = None):\n        super().__init__('minimap2')\n        self._target_index: Path = None\n        self._align_config: Minimap2AlignConfig = align_config or Minimap2AlignConfig()\n        self._index_config: Minimap2IndexConfig = index_config or Minimap2IndexConfig()\n        if targets:\n            self.build_index(targets)\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.cleanup()\n\n    def __del__(self):\n        self.cleanup()\n\n    def __call__(self, *args, **kwargs):\n        return self.align(*args, **kwargs)\n\n    def cleanup(self):\n        \"\"\"\n        Cleans up resources related to the target index if it is set.\n\n        This method checks if there is a target index specified and, if so, closes the\n        index to release any held resources. It also resets the target index\n        reference to None, ensuring subsequent operations do not attempt to access\n        a closed resource.\n\n        Raises:\n            No explicit exceptions are raised, but calling operations on a closed\n            resource externally could produce runtime errors.\n        \"\"\"\n        if self._target_index and not self._target_index.closed:\n            self._target_index.close()\n            self._target_index = None\n\n    @staticmethod\n    def _validate_seqs(*seqs: Union[str, Path, SeqFile, Record, Feature], pipe_arg: str = '-') -&gt; tuple[\n        str, [Union[str, None]]]:\n        \"\"\"\n        Checks query or target inputs based on the types passed\n        Returns:\n            A tuple of the argument to be passed to the subprocess and, if necessary, the piped input (or none)\n        \"\"\"\n        # If pipe, the input MUST be a mixture of str, Record, Feature, else MUST be Path, SeqFile\n        proc_arg, pipe = [], ''\n        for i in seqs:\n            if isinstance(i, (Path, SeqFile)):\n                # Check arg_types to make sure it doesn't contain pipe-able types (Record, Feature, str)\n                if pipe:\n                    raise Minimap2Error('Cannot mix pipe-able inputs with file-like inputs')\n                proc_arg.append(str(i))  # Requires SeqFile str representation to be SeqFile.path.__str__\n            else:\n                if proc_arg:\n                    raise Minimap2Error('Cannot mix pipe-able inputs with file-like inputs')\n                if isinstance(i, str):\n                    if not i.startswith('&gt;') or not i.startswith('@'):\n                        raise Minimap2Error('If input is a string, it must be in sequence format')\n                    pipe += i\n                else:\n                    pipe += format(i, 'fasta')\n\n        return ' '.join(proc_arg) if proc_arg else pipe_arg, pipe or None\n\n    def build_index(\n            self,\n            targets: Union[str, Path, SeqFile, Record, Feature, Iterable[Union[str, Path, SeqFile, Record, Feature]]],\n            config: Minimap2IndexConfig = None\n    ) -&gt; Path:\n        \"\"\"\n        Builds an index for the targets and writes to a temporary file\n\n        :param targets: The targets to index; can be a fasta-formatted string, path to a fasta file,\n                        ``Records`` or ``Features``\n        :returns: A Path to the temporary file containing the index\n        \"\"\"\n        arg, pipe = self._validate_seqs(*targets)\n        if not config:\n            config = self._index_config\n        if self._target_index is None:\n            self._target_index = NamedTemporaryFile()\n        _, stderr = self._run(f'{_build_params(config)} -d {self._target_index.name} {arg}', pipe, False)\n        if not is_non_empty_file(self._target_index.name):\n            self._target_index = None\n            raise Minimap2Error(f'Failed to build index, {stderr=}')\n        return Path(self._target_index.name)\n\n    def align(\n            self,\n            queries: Union[str, Path, SeqFile, Record, Feature, Iterable[Union[str, Path, SeqFile, Record, Feature]]],\n            targets: Union[str, Path, SeqFile, Record, Feature, Iterable[Union[str, Path, SeqFile, Record, Feature]]] = None,\n            config: Minimap2AlignConfig = None\n    ) -&gt; Generator[Alignment, None, None]:\n        \"\"\"\n        Aligns queries to targets.\n\n        :param queries: Alignment queries; can be a fasta-formatted string, path to a fasta file, ``Records`` or\n                        ``Features``\n\n        :param targets: Optional Alignment targets; can be a fasta-formatted string, path to a fasta file, ``Records``\n                        or ``Features``; will otherwise use the target index built at instantiation.\n                        If ``targets`` is passed and a target index exists, the target index is ignored.\n                        If ``query`` is not a path and ``targets`` is not a path, a new target index will need to be\n                        built, which will overwrite any existing target index, printing a ``Minimap2Warning``.\n\n        :returns: A generator of ``Alignment`` objects\n        \"\"\"\n        query_arg, query_pipe = self._validate_seqs(*queries)\n        if not config:\n            config = self._align_config\n        if targets:\n            target_arg, target_pipe = self._validate_seqs(*targets)\n            if query_pipe and target_pipe:  # Both are stdin, so we need to create the target index\n                if self._target_index:  # Existing target index, raise an error rather than overwriting\n                    warn('Overwriting existing target index', Minimap2Warning)\n                target_arg, target_pipe = self.build_index(targets).name, None\n        else:\n            if self._target_index:\n                target_arg, target_pipe = self._target_index.name, None\n            else:\n                raise Minimap2Error('Targets must be supplied if no target index has been built')\n\n        stdout, stderr = self._run(f'{_build_params(config)} {target_arg} {query_arg}', query_pipe or target_pipe)\n\n        for line in stdout.splitlines():\n            yield Alignment.from_sam(line) if config.a else Alignment.from_paf(line)\n</code></pre>"},{"location":"reference/eris/external/#eris.external.Minimap2.align","title":"<code>align(queries, targets=None, config=None)</code>","text":"<p>Aligns queries to targets.</p> <p>:param queries: Alignment queries; can be a fasta-formatted string, path to a fasta file, <code>Records</code> or                 <code>Features</code></p> <p>:param targets: Optional Alignment targets; can be a fasta-formatted string, path to a fasta file, <code>Records</code>                 or <code>Features</code>; will otherwise use the target index built at instantiation.                 If <code>targets</code> is passed and a target index exists, the target index is ignored.                 If <code>query</code> is not a path and <code>targets</code> is not a path, a new target index will need to be                 built, which will overwrite any existing target index, printing a <code>Minimap2Warning</code>.</p> <p>:returns: A generator of <code>Alignment</code> objects</p> Source code in <code>eris/external.py</code> <pre><code>def align(\n        self,\n        queries: Union[str, Path, SeqFile, Record, Feature, Iterable[Union[str, Path, SeqFile, Record, Feature]]],\n        targets: Union[str, Path, SeqFile, Record, Feature, Iterable[Union[str, Path, SeqFile, Record, Feature]]] = None,\n        config: Minimap2AlignConfig = None\n) -&gt; Generator[Alignment, None, None]:\n    \"\"\"\n    Aligns queries to targets.\n\n    :param queries: Alignment queries; can be a fasta-formatted string, path to a fasta file, ``Records`` or\n                    ``Features``\n\n    :param targets: Optional Alignment targets; can be a fasta-formatted string, path to a fasta file, ``Records``\n                    or ``Features``; will otherwise use the target index built at instantiation.\n                    If ``targets`` is passed and a target index exists, the target index is ignored.\n                    If ``query`` is not a path and ``targets`` is not a path, a new target index will need to be\n                    built, which will overwrite any existing target index, printing a ``Minimap2Warning``.\n\n    :returns: A generator of ``Alignment`` objects\n    \"\"\"\n    query_arg, query_pipe = self._validate_seqs(*queries)\n    if not config:\n        config = self._align_config\n    if targets:\n        target_arg, target_pipe = self._validate_seqs(*targets)\n        if query_pipe and target_pipe:  # Both are stdin, so we need to create the target index\n            if self._target_index:  # Existing target index, raise an error rather than overwriting\n                warn('Overwriting existing target index', Minimap2Warning)\n            target_arg, target_pipe = self.build_index(targets).name, None\n    else:\n        if self._target_index:\n            target_arg, target_pipe = self._target_index.name, None\n        else:\n            raise Minimap2Error('Targets must be supplied if no target index has been built')\n\n    stdout, stderr = self._run(f'{_build_params(config)} {target_arg} {query_arg}', query_pipe or target_pipe)\n\n    for line in stdout.splitlines():\n        yield Alignment.from_sam(line) if config.a else Alignment.from_paf(line)\n</code></pre>"},{"location":"reference/eris/external/#eris.external.Minimap2.build_index","title":"<code>build_index(targets, config=None)</code>","text":"<p>Builds an index for the targets and writes to a temporary file</p> <p>:param targets: The targets to index; can be a fasta-formatted string, path to a fasta file,                 <code>Records</code> or <code>Features</code> :returns: A Path to the temporary file containing the index</p> Source code in <code>eris/external.py</code> <pre><code>def build_index(\n        self,\n        targets: Union[str, Path, SeqFile, Record, Feature, Iterable[Union[str, Path, SeqFile, Record, Feature]]],\n        config: Minimap2IndexConfig = None\n) -&gt; Path:\n    \"\"\"\n    Builds an index for the targets and writes to a temporary file\n\n    :param targets: The targets to index; can be a fasta-formatted string, path to a fasta file,\n                    ``Records`` or ``Features``\n    :returns: A Path to the temporary file containing the index\n    \"\"\"\n    arg, pipe = self._validate_seqs(*targets)\n    if not config:\n        config = self._index_config\n    if self._target_index is None:\n        self._target_index = NamedTemporaryFile()\n    _, stderr = self._run(f'{_build_params(config)} -d {self._target_index.name} {arg}', pipe, False)\n    if not is_non_empty_file(self._target_index.name):\n        self._target_index = None\n        raise Minimap2Error(f'Failed to build index, {stderr=}')\n    return Path(self._target_index.name)\n</code></pre>"},{"location":"reference/eris/external/#eris.external.Minimap2.cleanup","title":"<code>cleanup()</code>","text":"<p>Cleans up resources related to the target index if it is set.</p> <p>This method checks if there is a target index specified and, if so, closes the index to release any held resources. It also resets the target index reference to None, ensuring subsequent operations do not attempt to access a closed resource.</p> Source code in <code>eris/external.py</code> <pre><code>def cleanup(self):\n    \"\"\"\n    Cleans up resources related to the target index if it is set.\n\n    This method checks if there is a target index specified and, if so, closes the\n    index to release any held resources. It also resets the target index\n    reference to None, ensuring subsequent operations do not attempt to access\n    a closed resource.\n\n    Raises:\n        No explicit exceptions are raised, but calling operations on a closed\n        resource externally could produce runtime errors.\n    \"\"\"\n    if self._target_index and not self._target_index.closed:\n        self._target_index.close()\n        self._target_index = None\n</code></pre>"},{"location":"reference/eris/external/#eris.external.Minimap2AlignConfig","title":"<code>Minimap2AlignConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Config</code></p> <p><code>dataclass</code> to handle CLI flags for Minimap2 alignment</p> Source code in <code>eris/external.py</code> <pre><code>@dataclass\nclass Minimap2AlignConfig(Config):\n    \"\"\"`dataclass` to handle CLI flags for Minimap2 alignment\"\"\"\n    x: Literal[\n        'lr:hq', 'splice', 'splice:hq', 'asm5', 'asm10', 'asm20', 'sr', 'map-pb', 'map-hifi', 'map-ont', 'map-iclr',\n        'ava-pb', 'ava-ont'\n    ] = None\n    t: int = RESOURCES.available_cpus  # Number of threads [3]\n    f: float = None  # filter out top FLOAT fraction of repetitive minimizers [0.0002]\n    g: int = None  # stop chain elongation if there are no minimizers in INT-bp [5000]\n    G: int = None  # max intron length (effective with -xsplice; changing -r) [200k]\n    F: int = None  # max fragment length (effective with -xsr or in the fragment mode) [800]\n    r: int = None  # chaining/alignment bandwidth and long-join bandwidth [500,20000]\n    n: int = None  # minimal number of minimizers on a chain [3]\n    m: int = None  #   minimal chaining score (matching bases minus log gap penalty) [40]\n    X: bool = False  # skip self and dual mappings (for the all-vs-all mode)\n    p: int = None  # min secondary-to-primary score ratio [0.8]\n    N: int = None  # retain at most INT secondary alignments [5]\n    A: int = None  # matching score [2]\n    B: int = None  # mismatch penalty (larger value for lower divergence) [4]\n    O: int = None  # gap open penalty [4,24]\n    E: int = None  # gap extension penalty; a k-long gap costs min{O1+k*E1,O2+k*E2} [2,1]\n    z: int = None  # Z-drop score and inversion Z-drop score [400,200]\n    s: int = None  # minimal peak DP alignment score [80]\n    u: Literal['f', 'b', 'n'] = None  # how to find GT-AG. f:transcript strand, b:both strands, n:don't match GT-AG [n]\n    J: Literal[0, 1] = None  # splice mode. 0: original minimap2 model; 1: miniprot model [1]\n    a: bool = False  # output in the SAM format (PAF by default)\n    c: bool = True  # output CIGAR in PAF\n    cs: bool = False  # output the cs tag; STR is 'short' (if absent) or 'long' [none]\n    ds: bool = False  # output the ds tag, which is an extension to cs\n    MD: bool = False  # output the MD tag\n    eqx: bool = False  # write =/X CIGAR operators\n    rev_only: bool = False\n    for_only: bool = False\n\n    @classmethod\n    def from_reads(cls, reads: ReadSet, **kwargs):\n        config = cls(**kwargs)\n        if reads.set_type in ['illumina', 'short']:\n            config.x = 'sr'\n        elif reads.set_type == 'pb':\n            config.x = 'map-pb'\n        elif reads.set_type == 'ont':\n            config.x = 'map-ont'\n        else:\n            config.x = 'lr:hq'\n        return config\n</code></pre>"},{"location":"reference/eris/external/#eris.external.Minimap2IndexConfig","title":"<code>Minimap2IndexConfig</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Config</code></p> <p><code>dataclass</code> to handle CLI flags for Minimap2 indexing</p> Source code in <code>eris/external.py</code> <pre><code>@dataclass\nclass Minimap2IndexConfig(Config):\n    \"\"\"`dataclass` to handle CLI flags for Minimap2 indexing\"\"\"\n    t: int = RESOURCES.available_cpus  # Number of threads [3]\n    H: bool = False  # use homopolymer-compressed k-mer (preferable for PacBio)\n    k: int = None  # k-mer size (no larger than 28) [15]\n    w: int = None  # minimizer window size [10]\n    I: int = None  # split index for every ~NUM input bases [8G]\n</code></pre>"},{"location":"reference/eris/graph/","title":"eris.graph","text":"<p>Module for handling simple networks, abolishing reliance on networkx.</p>"},{"location":"reference/eris/graph/#eris.graph.Edge","title":"<code>Edge</code>","text":"<p>General class to link objects together for graphs, supporting optional weights and attributes (such as strand). Objects must have an <code>id</code> attribute or be strings. Note, this class intentionally holds references to nodes rather than the instances themselves. Represents a directed connection from 'fr' to 'to'.</p> Source code in <code>eris/graph.py</code> <pre><code>class Edge:\n    \"\"\"\n    General class to link objects together for graphs, supporting optional weights and attributes (such as strand).\n    Objects must have an ``id`` attribute or be strings.\n    Note, this class intentionally holds references to nodes rather than the instances themselves.\n    Represents a directed connection from 'fr' to 'to'.\n    \"\"\"\n    def __init__(self, fr: Any, to: Any, fr_attribute: Any = None, to_attribute: Any = None,\n                 weight: Optional[float] = None): # Weight is optional\n        # Ensure node IDs are strings\n        self.fr = fr if isinstance(fr, str) else getattr(fr, 'id', str(fr)) # type: str\n        self.to = to if isinstance(to, str) else getattr(to, 'id', str(to))   # type: str\n        self.fr_attribute = fr_attribute\n        self.to_attribute = to_attribute\n        # Store the weight; it can be None if not provided\n        self.weight = weight\n\n    def __repr__(self):\n        weight_str = f\" (w={self.weight})\" if self.weight is not None else \"\"\n        # Represent the fundamental direction of the edge object\n        return f\"Edge({self.fr} -&gt; {self.to}{weight_str})\"\n\n    def __str__(self):\n        return self.__repr__()\n\n    def __format__(self, __format_spec: Literal['gfa', 'tsv'] = ''):\n        if __format_spec == '':\n            return self.__repr__()\n        elif __format_spec == 'gfa':\n            fr_orient = self.fr_attribute if self.fr_attribute in ['+', '-'] else '+'\n            to_orient = self.to_attribute if self.to_attribute in ['+', '-'] else '+'\n            # Optional weight tag could be added: f\" W:{self.weight}\"? Standard is less clear.\n            return f\"L\\t{self.fr}\\t{fr_orient}\\t{self.to}\\t{to_orient}\\t*\\n\"\n        elif __format_spec == 'tsv':\n            weight_str = f\"\\t{self.weight}\" if self.weight is not None else \"\\t\" # Add empty tab if no weight\n            return f\"{self.fr}\\t{self.to}{weight_str}\\n\"\n        else:\n            raise NotImplementedError(f'Format \"{__format_spec}\" not supported')\n\n    # Equality and hash methods include weight\n    def __eq__(self, other):\n        if not isinstance(other, Edge):\n            return NotImplemented\n        # Direction matters for edge equality itself\n        return (self.fr == other.fr and self.to == other.to and\n                self.fr_attribute == other.fr_attribute and\n                self.to_attribute == other.to_attribute and\n                self.weight == other.weight) # Compare weight too\n\n    def __hash__(self):\n        # Hash includes weight and direction\n        return hash((self.fr, self.to, self.fr_attribute, self.to_attribute, self.weight))\n\n    def reverse(self) -&gt; 'Edge':\n        \"\"\"Returns a new Edge object representing the reverse direction.\"\"\"\n        return Edge(self.to, self.fr, self.to_attribute, self.fr_attribute, self.weight)\n</code></pre>"},{"location":"reference/eris/graph/#eris.graph.Edge.reverse","title":"<code>reverse()</code>","text":"<p>Returns a new Edge object representing the reverse direction.</p> Source code in <code>eris/graph.py</code> <pre><code>def reverse(self) -&gt; 'Edge':\n    \"\"\"Returns a new Edge object representing the reverse direction.\"\"\"\n    return Edge(self.to, self.fr, self.to_attribute, self.fr_attribute, self.weight)\n</code></pre>"},{"location":"reference/eris/graph/#eris.graph.Graph","title":"<code>Graph</code>","text":"<p>Represents a graph that can be either directed or undirected. Nodes are identified by string IDs. Edges are stored, and connectivity is managed based on the 'directed' flag.</p> Source code in <code>eris/graph.py</code> <pre><code>class Graph:\n    \"\"\"\n    Represents a graph that can be either directed or undirected.\n    Nodes are identified by string IDs.\n    Edges are stored, and connectivity is managed based on the 'directed' flag.\n    \"\"\"\n    def __init__(self, *edges: Edge, directed: bool = True):\n        \"\"\"\n        Initializes the graph.\n\n        Args:\n            *edges: Variable number of Edge objects to initialize the graph with.\n            directed: If True (default), the graph is treated as directed.\n                      If False, the graph is treated as undirected, meaning adding an\n                      edge A-&gt;B also allows traversal B-&gt;A with the same weight.\n        \"\"\"\n        # Adjacency list: maps node ID to a set of outgoing Edge objects *starting* from that node.\n        # For undirected graphs, this will include edges representing reverse traversal.\n        self.adj: Dict[str, Set[Edge]] = defaultdict(set)\n        # Set of unique Edge objects fundamentally added to the graph.\n        self.edges: Set[Edge] = set()\n        self._node_ids: Set[str] = set()\n        self.directed: bool = directed\n\n        for edge in edges:\n            self.add_edge(edge)\n\n    def __repr__(self):\n        # Note: len(self.edges) counts only the *unique* edge objects added,\n        # not the total number of traversable connections in the undirected case.\n        return f\"{'Directed' if self.directed else 'Undirected'} Graph with {len(self._node_ids)} nodes and {len(self.edges)} defined edges\"\n\n    def __str__(self):\n        return self.__repr__()\n\n    def add_edge(self, edge: Edge):\n        \"\"\"\n        Adds an edge to the graph.\n\n        If the graph is undirected (self.directed=False), adding edge (fr -&gt; to)\n        will allow traversal in both directions (fr -&gt; to and to -&gt; fr) with the\n        same weight and reversed attributes. The original edge object is added\n        to self.edges, but the adjacency list (self.adj) reflects reachability\n        in both directions.\n        \"\"\"\n        # Add the nodes to the set of known node IDs\n        self._node_ids.add(edge.fr)\n        self._node_ids.add(edge.to)\n\n        # This helps track the originally added edges vs implicit reverse ones\n        if edge not in self.edges:  # is_new_edge\n             self.edges.add(edge)  # Add the primary edge representation if it's new\n\n        # Check if this specific edge object is already in the adjacency list for the 'fr' node\n        if edge not in self.adj[edge.fr]:  # Add forward connectivity to the adjacency list\n            self.adj[edge.fr].add(edge)\n\n        # If the graph is undirected, add reverse connectivity as well\n        if not self.directed:\n            # Create a conceptual reverse edge for traversal and add to the adjacency list of the 'to' node\n            # Check if this specific reverse edge object is already in the adj list for the 'to' node\n            if (reverse_edge := edge.reverse()) not in self.adj[edge.to]:\n                self.adj[edge.to].add(reverse_edge)\n            # Note: We do not add the reverse_edge to self.edges unless it's explicitly added later by the user\n\n    def get_neighbors(self, node_id: str) -&gt; Set[Edge]:\n        \"\"\"\n        Returns the set of outgoing edges for a given node ID, respecting\n        graph directionality (for undirected graphs, this includes edges\n        allowing traversal back along an added edge).\n        \"\"\"\n        return self.adj.get(node_id, set())\n</code></pre>"},{"location":"reference/eris/graph/#eris.graph.Graph.__init__","title":"<code>__init__(*edges, directed=True)</code>","text":"<p>Initializes the graph.</p> <p>Parameters:</p> Name Type Description Default <code>*edges</code> <code>Edge</code> <p>Variable number of Edge objects to initialize the graph with.</p> <code>()</code> <code>directed</code> <code>bool</code> <p>If True (default), the graph is treated as directed.       If False, the graph is treated as undirected, meaning adding an       edge A-&gt;B also allows traversal B-&gt;A with the same weight.</p> <code>True</code> Source code in <code>eris/graph.py</code> <pre><code>def __init__(self, *edges: Edge, directed: bool = True):\n    \"\"\"\n    Initializes the graph.\n\n    Args:\n        *edges: Variable number of Edge objects to initialize the graph with.\n        directed: If True (default), the graph is treated as directed.\n                  If False, the graph is treated as undirected, meaning adding an\n                  edge A-&gt;B also allows traversal B-&gt;A with the same weight.\n    \"\"\"\n    # Adjacency list: maps node ID to a set of outgoing Edge objects *starting* from that node.\n    # For undirected graphs, this will include edges representing reverse traversal.\n    self.adj: Dict[str, Set[Edge]] = defaultdict(set)\n    # Set of unique Edge objects fundamentally added to the graph.\n    self.edges: Set[Edge] = set()\n    self._node_ids: Set[str] = set()\n    self.directed: bool = directed\n\n    for edge in edges:\n        self.add_edge(edge)\n</code></pre>"},{"location":"reference/eris/graph/#eris.graph.Graph.add_edge","title":"<code>add_edge(edge)</code>","text":"<p>Adds an edge to the graph.</p> <p>If the graph is undirected (self.directed=False), adding edge (fr -&gt; to) will allow traversal in both directions (fr -&gt; to and to -&gt; fr) with the same weight and reversed attributes. The original edge object is added to self.edges, but the adjacency list (self.adj) reflects reachability in both directions.</p> Source code in <code>eris/graph.py</code> <pre><code>def add_edge(self, edge: Edge):\n    \"\"\"\n    Adds an edge to the graph.\n\n    If the graph is undirected (self.directed=False), adding edge (fr -&gt; to)\n    will allow traversal in both directions (fr -&gt; to and to -&gt; fr) with the\n    same weight and reversed attributes. The original edge object is added\n    to self.edges, but the adjacency list (self.adj) reflects reachability\n    in both directions.\n    \"\"\"\n    # Add the nodes to the set of known node IDs\n    self._node_ids.add(edge.fr)\n    self._node_ids.add(edge.to)\n\n    # This helps track the originally added edges vs implicit reverse ones\n    if edge not in self.edges:  # is_new_edge\n         self.edges.add(edge)  # Add the primary edge representation if it's new\n\n    # Check if this specific edge object is already in the adjacency list for the 'fr' node\n    if edge not in self.adj[edge.fr]:  # Add forward connectivity to the adjacency list\n        self.adj[edge.fr].add(edge)\n\n    # If the graph is undirected, add reverse connectivity as well\n    if not self.directed:\n        # Create a conceptual reverse edge for traversal and add to the adjacency list of the 'to' node\n        # Check if this specific reverse edge object is already in the adj list for the 'to' node\n        if (reverse_edge := edge.reverse()) not in self.adj[edge.to]:\n            self.adj[edge.to].add(reverse_edge)\n</code></pre>"},{"location":"reference/eris/graph/#eris.graph.Graph.get_neighbors","title":"<code>get_neighbors(node_id)</code>","text":"<p>Returns the set of outgoing edges for a given node ID, respecting graph directionality (for undirected graphs, this includes edges allowing traversal back along an added edge).</p> Source code in <code>eris/graph.py</code> <pre><code>def get_neighbors(self, node_id: str) -&gt; Set[Edge]:\n    \"\"\"\n    Returns the set of outgoing edges for a given node ID, respecting\n    graph directionality (for undirected graphs, this includes edges\n    allowing traversal back along an added edge).\n    \"\"\"\n    return self.adj.get(node_id, set())\n</code></pre>"},{"location":"reference/eris/io/","title":"eris.io","text":"<p>Module for parsing and managing bacterial sequence files and data.</p>"},{"location":"reference/eris/io/#eris.io.Genome","title":"<code>Genome</code>","text":"<p>A class representing a single genome assembly in memory with contigs and potentially edges</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>The ID of the genome.</p> <code>contigs</code> <code>dict[str:Record]</code> <p>A dictionary of contig IDs as keys and Record objects as values.</p> <code>edges</code> <code>list[Edge]</code> <p>A list of Edges connecting the contigs.</p> <code>is_annotated</code> <code>bool</code> <p>True if the genome has been loaded with annotations (e.g. from Genbank / GFF / BED).</p> Source code in <code>eris/io.py</code> <pre><code>class Genome:\n    \"\"\"\n    A class representing a single genome assembly in memory with contigs and potentially edges\n\n    Attributes:\n        id: The ID of the genome.\n        contigs: A dictionary of contig IDs as keys and Record objects as values.\n        edges: A list of Edges connecting the contigs.\n        is_annotated: True if the genome has been loaded with annotations (e.g. from Genbank / GFF / BED).\n    \"\"\"\n    def __init__(self, id_: str, contigs: dict[str: 'Record'] = None, edges: list[Edge] = None):\n        \"\"\"Represents a single bacterial genome to be loaded into memory from a file\"\"\"\n        self.id: str = id_\n        self.contigs: dict[str: 'Record'] = contigs or {}\n        self.edges: list[Edge] = edges or []\n        self.is_annotated: bool = False\n\n    def __len__(self):\n        return sum(len(i) for i in self.contigs.values())\n\n    def __iter__(self):\n        return iter(self.contigs.values())\n\n    def __str__(self):\n        return self.id\n\n    def __getitem__(self, item: str) -&gt; 'Record':\n        return self.contigs[item]\n\n    def __format__(self, __format_spec: Literal['fasta', 'fna', 'ffn', 'faa', 'bed', 'gfa'] = ''):\n        if __format_spec == '':\n            return self.__str__()\n        elif __format_spec in {'fasta', 'fna', 'ffn', 'faa', 'bed'}:\n            return ''.join(format(i, __format_spec) for i in self.contigs.values())\n        elif __format_spec == 'gfa':\n            return ''.join(format(i, __format_spec) for i in chain(self.contigs.values(), self.edges))\n        else:\n            raise NotImplementedError(f'Invalid format: {__format_spec}')\n\n    @classmethod\n    def from_file(cls, file: Union[str, Path, IO, SeqFile], annotations: Union[str, Path, SeqFile] = None):\n        \"\"\"\n        Loads a genome from a file with optional annotations, e.g. a FASTA with a BED/GFF file.\n        :param file: Path to file (str/Path) or a SeqFile instance.\n        :param annotations: Optional annotations as a file path (str/Path) or SeqFile instance.\n        :return: A Genome instance representing the genome in memory\n        \"\"\"\n        file = SeqFile(file) if not isinstance(file, SeqFile) else file\n        self = cls(file.id)\n        for record in file:\n            if isinstance(record, Record):\n                self.contigs[record.id] = record\n                if not file.format == 'gfa' and next((v for k, v in record.qualifiers if k == 'topology'),\n                                                     'linear') == 'circular':\n                    self.edges.append(Edge(record.id, record.id, 1, 1))  # Add self loop for circular genomes\n                    # We assume a GFA file already has this edge but this may not be the case\n            elif isinstance(record, Edge):\n                self.edges.append(record)\n        if annotations:\n            if file.format not in {'fasta', 'gfa'}:\n                raise GenomeError(f'Can only provide annotations to FASTA and GFA files, not {file.format}')\n            annotations = SeqFile(annotations) if not isinstance(annotations, SeqFile) else annotations\n            if not annotations.format in {'gff', 'bed'}:\n                raise GenomeError(f'Annotations must be in GFF or BED format, not {annotations.format}')\n            for contig_id, features in grouper(annotations, 'location.parent_id'):  # Sort by contig id\n                if contig := self.contigs.get(contig_id):  # type: Record\n                    contig.add_features(*features)\n                    self.is_annotated = True\n        return self\n\n    @classmethod\n    def random(\n            cls, id_: str = None, genome: Record = None, rng: Random = None, n_contigs: int = None,\n            min_contigs: int = 1, max_contigs: int = 1000, gc: float = 0.5, length: int = None, min_len: int = 10,\n            max_len: int = 5000000\n    ):\n        \"\"\"\n        Generates a random genome assembly for testing purposes.\n\n        :param id_: ID of the genome, if not provided a random one will be generated\n        :param genome: Initial genome record; if not provided a random one will be generated\n        :param rng: Random number generator.\n        :param n_contigs: Number of contigs in the assembly. If not provided, a random number of contigs will be generated.\n        :param min_contigs: Minimum number of contigs if n_contigs is not specified.\n        :param max_contigs: Maximum number of contigs if n_contigs is not specified.\n        :param gc: GC content of the genome.\n        :param length: Total length of the genome. If not provided, a random length will be generated.\n        :param min_len: Minimum length of the genome if length is not specified.\n        :param max_len: Maximum length of the genome if length is not specified.\n        :return: A Genome instance representing the random assembly.\n        \"\"\"\n        if rng is None:\n            rng = RESOURCES.rng\n        return cls(id_ or str(uuid4()), {i.id: i for i in (genome or Record.random(\n            None, DNA, rng, gc, length, min_len, max_len)).shred(rng, n_contigs or rng.randint(min_contigs, max_contigs))})\n\n    def as_assembly_graph(self, directed: bool = False) -&gt; Graph:\n        \"\"\"\n        Returns the assembly as a graph where contigs are nodes\n        \"\"\"\n        return Graph(*self.edges, directed=directed)\n\n    def as_feature_graph(self, directed: bool = False) -&gt; Graph:\n        \"\"\"\n        Returns the assembly as a graph where features are nodes.\n        Adjacent features on the same contig are connected. Features at the termini\n        of connected contigs are also connected.\n        \"\"\"\n        feature_graph = Graph(directed=directed)\n\n        # 1. Add intra-contig edges (connecting adjacent features on the same contig)\n        for contig in self.contigs.values():\n            if contig.features:\n                # This assumes contig.as_edge_list() correctly connects adjacent features\n                for edge in contig.as_edge_list():\n                    feature_graph.add_edge(edge)\n\n        # 2. Add inter-contig edges by iterating through all assembly connections\n        for edge in self.as_assembly_graph(directed=directed).edges:\n            # Get the original 'from' and 'to' contigs for this edge\n            fr_contig_orig, to_contig_orig = self.contigs.get(edge.fr), self.contigs.get(edge.to)\n\n            # Skip if either contig is missing or has no features\n            if not (fr_contig_orig and fr_contig_orig.features) or not (to_contig_orig and to_contig_orig.features):\n                continue\n\n            # Determine the correct orientation based on the assembly edge attributes\n            fr_contig = fr_contig_orig.reverse_complement() if edge.fr_attribute == -1 else fr_contig_orig\n            to_contig = to_contig_orig.reverse_complement() if edge.to_attribute == -1 else to_contig_orig\n\n            # Identify the terminal features on the correctly oriented contigs\n            fr_feature = fr_contig.features[-1]  # The last feature on the 'from' contig\n            to_feature = to_contig.features[0]  # The first feature on the 'to' contig\n\n            # Calculate the gap distance between the features\n            distance = (len(fr_contig) - fr_feature.location.end) + to_feature.location.start\n\n            feature_graph.add_edge(  # Add the new edge connecting the two features\n                Edge(\n                    fr_feature.id,\n                    to_feature.id,\n                    fr_feature.location.strand,\n                    to_feature.location.strand,\n                    distance\n                )\n            )\n\n        return feature_graph\n\n    @require('pyrodigal')\n    def find_genes(self, gene_finder: 'pyrodigal.GeneFinder' = None, pool: 'Executor' = None,\n                   config: GeneFinderConfig = None) -&gt; Generator[Feature, None, None]:\n        \"\"\"\n        Predicts ORFs in the Genome using Pyrodigal.\n\n        Parameters:\n            gene_finder: An optional pre-trained pyrodigal.GeneFinder instance. If not provided, one will be\n                         initialized using the config parameter.\n            pool: An optional Executor (e.g., ThreadPoolExecutor or ProcessPoolExecutor)\n                  to parallelize gene finding across contigs. If None, a ThreadPoolExecutor will be created.\n            config: A GeneFinderConfig object to configure the Pyrodigal GeneFinder. Only used if gene_finder\n                    is None.\n\n        Yields:\n            Feature objects representing the predicted CDS (Coding Sequence) genes.\n\n        Notes:\n            - Requires pyrodigal to be installed.\n        \"\"\"\n        from pyrodigal import __version__ as _pyrodigal_version\n        from pyrodigal import Gene\n\n        if gene_finder is None:\n            from pyrodigal import GeneFinder\n            gene_finder = GeneFinder(**asdict(config or GeneFinderConfig()))\n\n        if gene_finder.training_info is None:\n            gene_finder.train(*(bytes(contig.seq) for contig in self.contigs.values()))\n\n        if pool is None:\n            pool = RESOURCES.pool\n\n        n = 0  # Gene counter\n        for contig, genes in zip(\n                self.contigs.values(),\n                pool.map(lambda contig: gene_finder.find_genes(bytes(contig.seq)), self.contigs.values())\n        ):\n            features = []\n            for gene in genes:  # type: Gene\n                features.append(cds := Feature(\n                    id_=f'{contig.id}_{n + 1:05d}', kind='CDS', seq=Seq(gene.sequence(), 'DNA'),\n                    location=Location(gene.begin - 1, gene.end, gene.strand, gene.partial_begin, gene.partial_end,\n                                      contig.id),\n                    qualifiers=[\n                        Qualifier('translation', Seq(gene.translate(), 'Amino')),\n                        Qualifier('transl_table', gene.translation_table),\n                        Qualifier('inference', f'ab initio prediction:Pyrodigal:{_pyrodigal_version}'),\n                        Qualifier('GC', gene.gc_cont),\n                        Qualifier('rbs_motif', gene.rbs_motif),\n                        Qualifier('rbs_spacer', gene.rbs_spacer)\n                    ]\n                ))\n                n += 1  # Increment the counter\n                yield cds  # Yield the CDS for potential use\n\n            contig.add_features(*features)  # Use the add_features method to sort with existing features\n\n        if n &gt; 0:  # If genes were found, mark the genome as annotated\n            self.is_annotated = True\n</code></pre>"},{"location":"reference/eris/io/#eris.io.Genome.__init__","title":"<code>__init__(id_, contigs=None, edges=None)</code>","text":"<p>Represents a single bacterial genome to be loaded into memory from a file</p> Source code in <code>eris/io.py</code> <pre><code>def __init__(self, id_: str, contigs: dict[str: 'Record'] = None, edges: list[Edge] = None):\n    \"\"\"Represents a single bacterial genome to be loaded into memory from a file\"\"\"\n    self.id: str = id_\n    self.contigs: dict[str: 'Record'] = contigs or {}\n    self.edges: list[Edge] = edges or []\n    self.is_annotated: bool = False\n</code></pre>"},{"location":"reference/eris/io/#eris.io.Genome.as_assembly_graph","title":"<code>as_assembly_graph(directed=False)</code>","text":"<p>Returns the assembly as a graph where contigs are nodes</p> Source code in <code>eris/io.py</code> <pre><code>def as_assembly_graph(self, directed: bool = False) -&gt; Graph:\n    \"\"\"\n    Returns the assembly as a graph where contigs are nodes\n    \"\"\"\n    return Graph(*self.edges, directed=directed)\n</code></pre>"},{"location":"reference/eris/io/#eris.io.Genome.as_feature_graph","title":"<code>as_feature_graph(directed=False)</code>","text":"<p>Returns the assembly as a graph where features are nodes. Adjacent features on the same contig are connected. Features at the termini of connected contigs are also connected.</p> Source code in <code>eris/io.py</code> <pre><code>def as_feature_graph(self, directed: bool = False) -&gt; Graph:\n    \"\"\"\n    Returns the assembly as a graph where features are nodes.\n    Adjacent features on the same contig are connected. Features at the termini\n    of connected contigs are also connected.\n    \"\"\"\n    feature_graph = Graph(directed=directed)\n\n    # 1. Add intra-contig edges (connecting adjacent features on the same contig)\n    for contig in self.contigs.values():\n        if contig.features:\n            # This assumes contig.as_edge_list() correctly connects adjacent features\n            for edge in contig.as_edge_list():\n                feature_graph.add_edge(edge)\n\n    # 2. Add inter-contig edges by iterating through all assembly connections\n    for edge in self.as_assembly_graph(directed=directed).edges:\n        # Get the original 'from' and 'to' contigs for this edge\n        fr_contig_orig, to_contig_orig = self.contigs.get(edge.fr), self.contigs.get(edge.to)\n\n        # Skip if either contig is missing or has no features\n        if not (fr_contig_orig and fr_contig_orig.features) or not (to_contig_orig and to_contig_orig.features):\n            continue\n\n        # Determine the correct orientation based on the assembly edge attributes\n        fr_contig = fr_contig_orig.reverse_complement() if edge.fr_attribute == -1 else fr_contig_orig\n        to_contig = to_contig_orig.reverse_complement() if edge.to_attribute == -1 else to_contig_orig\n\n        # Identify the terminal features on the correctly oriented contigs\n        fr_feature = fr_contig.features[-1]  # The last feature on the 'from' contig\n        to_feature = to_contig.features[0]  # The first feature on the 'to' contig\n\n        # Calculate the gap distance between the features\n        distance = (len(fr_contig) - fr_feature.location.end) + to_feature.location.start\n\n        feature_graph.add_edge(  # Add the new edge connecting the two features\n            Edge(\n                fr_feature.id,\n                to_feature.id,\n                fr_feature.location.strand,\n                to_feature.location.strand,\n                distance\n            )\n        )\n\n    return feature_graph\n</code></pre>"},{"location":"reference/eris/io/#eris.io.Genome.find_genes","title":"<code>find_genes(gene_finder=None, pool=None, config=None)</code>","text":"<p>Predicts ORFs in the Genome using Pyrodigal.</p> <p>Parameters:</p> Name Type Description Default <code>gene_finder</code> <code>GeneFinder</code> <p>An optional pre-trained pyrodigal.GeneFinder instance. If not provided, one will be          initialized using the config parameter.</p> <code>None</code> <code>pool</code> <code>Executor</code> <p>An optional Executor (e.g., ThreadPoolExecutor or ProcessPoolExecutor)   to parallelize gene finding across contigs. If None, a ThreadPoolExecutor will be created.</p> <code>None</code> <code>config</code> <code>GeneFinderConfig</code> <p>A GeneFinderConfig object to configure the Pyrodigal GeneFinder. Only used if gene_finder     is None.</p> <code>None</code> <p>Yields:</p> Type Description <code>Feature</code> <p>Feature objects representing the predicted CDS (Coding Sequence) genes.</p> Notes <ul> <li>Requires pyrodigal to be installed.</li> </ul> Source code in <code>eris/io.py</code> <pre><code>@require('pyrodigal')\ndef find_genes(self, gene_finder: 'pyrodigal.GeneFinder' = None, pool: 'Executor' = None,\n               config: GeneFinderConfig = None) -&gt; Generator[Feature, None, None]:\n    \"\"\"\n    Predicts ORFs in the Genome using Pyrodigal.\n\n    Parameters:\n        gene_finder: An optional pre-trained pyrodigal.GeneFinder instance. If not provided, one will be\n                     initialized using the config parameter.\n        pool: An optional Executor (e.g., ThreadPoolExecutor or ProcessPoolExecutor)\n              to parallelize gene finding across contigs. If None, a ThreadPoolExecutor will be created.\n        config: A GeneFinderConfig object to configure the Pyrodigal GeneFinder. Only used if gene_finder\n                is None.\n\n    Yields:\n        Feature objects representing the predicted CDS (Coding Sequence) genes.\n\n    Notes:\n        - Requires pyrodigal to be installed.\n    \"\"\"\n    from pyrodigal import __version__ as _pyrodigal_version\n    from pyrodigal import Gene\n\n    if gene_finder is None:\n        from pyrodigal import GeneFinder\n        gene_finder = GeneFinder(**asdict(config or GeneFinderConfig()))\n\n    if gene_finder.training_info is None:\n        gene_finder.train(*(bytes(contig.seq) for contig in self.contigs.values()))\n\n    if pool is None:\n        pool = RESOURCES.pool\n\n    n = 0  # Gene counter\n    for contig, genes in zip(\n            self.contigs.values(),\n            pool.map(lambda contig: gene_finder.find_genes(bytes(contig.seq)), self.contigs.values())\n    ):\n        features = []\n        for gene in genes:  # type: Gene\n            features.append(cds := Feature(\n                id_=f'{contig.id}_{n + 1:05d}', kind='CDS', seq=Seq(gene.sequence(), 'DNA'),\n                location=Location(gene.begin - 1, gene.end, gene.strand, gene.partial_begin, gene.partial_end,\n                                  contig.id),\n                qualifiers=[\n                    Qualifier('translation', Seq(gene.translate(), 'Amino')),\n                    Qualifier('transl_table', gene.translation_table),\n                    Qualifier('inference', f'ab initio prediction:Pyrodigal:{_pyrodigal_version}'),\n                    Qualifier('GC', gene.gc_cont),\n                    Qualifier('rbs_motif', gene.rbs_motif),\n                    Qualifier('rbs_spacer', gene.rbs_spacer)\n                ]\n            ))\n            n += 1  # Increment the counter\n            yield cds  # Yield the CDS for potential use\n\n        contig.add_features(*features)  # Use the add_features method to sort with existing features\n\n    if n &gt; 0:  # If genes were found, mark the genome as annotated\n        self.is_annotated = True\n</code></pre>"},{"location":"reference/eris/io/#eris.io.Genome.from_file","title":"<code>from_file(file, annotations=None)</code>  <code>classmethod</code>","text":"<p>Loads a genome from a file with optional annotations, e.g. a FASTA with a BED/GFF file. :param file: Path to file (str/Path) or a SeqFile instance. :param annotations: Optional annotations as a file path (str/Path) or SeqFile instance. :return: A Genome instance representing the genome in memory</p> Source code in <code>eris/io.py</code> <pre><code>@classmethod\ndef from_file(cls, file: Union[str, Path, IO, SeqFile], annotations: Union[str, Path, SeqFile] = None):\n    \"\"\"\n    Loads a genome from a file with optional annotations, e.g. a FASTA with a BED/GFF file.\n    :param file: Path to file (str/Path) or a SeqFile instance.\n    :param annotations: Optional annotations as a file path (str/Path) or SeqFile instance.\n    :return: A Genome instance representing the genome in memory\n    \"\"\"\n    file = SeqFile(file) if not isinstance(file, SeqFile) else file\n    self = cls(file.id)\n    for record in file:\n        if isinstance(record, Record):\n            self.contigs[record.id] = record\n            if not file.format == 'gfa' and next((v for k, v in record.qualifiers if k == 'topology'),\n                                                 'linear') == 'circular':\n                self.edges.append(Edge(record.id, record.id, 1, 1))  # Add self loop for circular genomes\n                # We assume a GFA file already has this edge but this may not be the case\n        elif isinstance(record, Edge):\n            self.edges.append(record)\n    if annotations:\n        if file.format not in {'fasta', 'gfa'}:\n            raise GenomeError(f'Can only provide annotations to FASTA and GFA files, not {file.format}')\n        annotations = SeqFile(annotations) if not isinstance(annotations, SeqFile) else annotations\n        if not annotations.format in {'gff', 'bed'}:\n            raise GenomeError(f'Annotations must be in GFF or BED format, not {annotations.format}')\n        for contig_id, features in grouper(annotations, 'location.parent_id'):  # Sort by contig id\n            if contig := self.contigs.get(contig_id):  # type: Record\n                contig.add_features(*features)\n                self.is_annotated = True\n    return self\n</code></pre>"},{"location":"reference/eris/io/#eris.io.Genome.random","title":"<code>random(id_=None, genome=None, rng=None, n_contigs=None, min_contigs=1, max_contigs=1000, gc=0.5, length=None, min_len=10, max_len=5000000)</code>  <code>classmethod</code>","text":"<p>Generates a random genome assembly for testing purposes.</p> <p>:param id_: ID of the genome, if not provided a random one will be generated :param genome: Initial genome record; if not provided a random one will be generated :param rng: Random number generator. :param n_contigs: Number of contigs in the assembly. If not provided, a random number of contigs will be generated. :param min_contigs: Minimum number of contigs if n_contigs is not specified. :param max_contigs: Maximum number of contigs if n_contigs is not specified. :param gc: GC content of the genome. :param length: Total length of the genome. If not provided, a random length will be generated. :param min_len: Minimum length of the genome if length is not specified. :param max_len: Maximum length of the genome if length is not specified. :return: A Genome instance representing the random assembly.</p> Source code in <code>eris/io.py</code> <pre><code>@classmethod\ndef random(\n        cls, id_: str = None, genome: Record = None, rng: Random = None, n_contigs: int = None,\n        min_contigs: int = 1, max_contigs: int = 1000, gc: float = 0.5, length: int = None, min_len: int = 10,\n        max_len: int = 5000000\n):\n    \"\"\"\n    Generates a random genome assembly for testing purposes.\n\n    :param id_: ID of the genome, if not provided a random one will be generated\n    :param genome: Initial genome record; if not provided a random one will be generated\n    :param rng: Random number generator.\n    :param n_contigs: Number of contigs in the assembly. If not provided, a random number of contigs will be generated.\n    :param min_contigs: Minimum number of contigs if n_contigs is not specified.\n    :param max_contigs: Maximum number of contigs if n_contigs is not specified.\n    :param gc: GC content of the genome.\n    :param length: Total length of the genome. If not provided, a random length will be generated.\n    :param min_len: Minimum length of the genome if length is not specified.\n    :param max_len: Maximum length of the genome if length is not specified.\n    :return: A Genome instance representing the random assembly.\n    \"\"\"\n    if rng is None:\n        rng = RESOURCES.rng\n    return cls(id_ or str(uuid4()), {i.id: i for i in (genome or Record.random(\n        None, DNA, rng, gc, length, min_len, max_len)).shred(rng, n_contigs or rng.randint(min_contigs, max_contigs))})\n</code></pre>"},{"location":"reference/eris/io/#eris.io.ReadFile","title":"<code>ReadFile</code>","text":"<p>               Bases: <code>SeqFile</code></p> <p>A subclass of :class:<code>~eris.core.io.SeqFile</code> that specifically handles a single file of sequencing reads in FASTQ format. This class extracts and stores read-specific information from the filename, and is designed to be used with the :class:<code>~eris.core.io.ReadSet</code> class.</p> <p>Attributes:</p> Name Type Description <code>sample_name</code> <p>The name of the sample from which the reads were derived.</p> <code>read_type</code> <p>The type of read ('short', 'illumina', 'long', 'pb', 'ont', or 'unknown').</p> <code>sample_number</code> <p>The sample number (for Illumina reads).</p> <code>lane_number</code> <p>The lane number (for Illumina reads).</p> <code>read_number</code> <p>The read number (1 or 2 for paired-end reads).</p> <code>index_number</code> <p>The index number (for Illumina reads).</p> Source code in <code>eris/io.py</code> <pre><code>class ReadFile(SeqFile):\n    \"\"\"\n    A subclass of :class:`~eris.core.io.SeqFile` that specifically handles a single file of sequencing reads\n    in FASTQ format.\n    This class extracts and stores read-specific information from the filename, and is designed to be used with the\n    :class:`~eris.core.io.ReadSet` class.\n\n    Attributes:\n        sample_name: The name of the sample from which the reads were derived.\n        read_type: The type of read ('short', 'illumina', 'long', 'pb', 'ont', or 'unknown').\n        sample_number: The sample number (for Illumina reads).\n        lane_number: The lane number (for Illumina reads).\n        read_number: The read number (1 or 2 for paired-end reads).\n        index_number: The index number (for Illumina reads).\n    \"\"\"\n    def __init__(self, file: Union[str, Path]):\n        \"\"\"\n        :param file: Path to file (str/Path) or an IO stream (binary or text).\n        \"\"\"\n        super().__init__(file)\n        self.sample_name = self.id\n        self._read_type: Literal['unknown', 'short', 'illumina', 'long', 'pb', 'ont'] = 'unknown'\n        self._sample_number: int = 0\n        self._lane_number: int = 0\n        self._read_number: int = 0\n        self._index_number: int = 0\n        if m := _ILLUMINA_READ_REGEX.match(self.id):\n            self.sample_name = m.group('sample_name')\n            self._read_type = \"illumina\"\n            self._sample_number = int(m.group('sample_number'))\n            self._lane_number = int(m.group('lane_number'))\n            self._read_number = int(m.group('read_number'))\n            self._index_number = int(m.group('index_number'))\n        elif m := _SHORT_READ_REGEX.match(self.id):\n            self.sample_name = m.group('sample_name')\n            self._read_type = \"short\"\n            self._read_number = int(m.group('read_number'))\n\n    @property\n    def read_type(self):\n        return self._read_type\n\n    @property\n    def sample_number(self):\n        return self._sample_number\n\n    @property\n    def lane_number(self):\n        return self._lane_number\n\n    @property\n    def read_number(self):\n        return self._read_number\n\n    @property\n    def index_number(self):\n        return self._index_number\n</code></pre>"},{"location":"reference/eris/io/#eris.io.ReadFile.__init__","title":"<code>__init__(file)</code>","text":"<p>:param file: Path to file (str/Path) or an IO stream (binary or text).</p> Source code in <code>eris/io.py</code> <pre><code>def __init__(self, file: Union[str, Path]):\n    \"\"\"\n    :param file: Path to file (str/Path) or an IO stream (binary or text).\n    \"\"\"\n    super().__init__(file)\n    self.sample_name = self.id\n    self._read_type: Literal['unknown', 'short', 'illumina', 'long', 'pb', 'ont'] = 'unknown'\n    self._sample_number: int = 0\n    self._lane_number: int = 0\n    self._read_number: int = 0\n    self._index_number: int = 0\n    if m := _ILLUMINA_READ_REGEX.match(self.id):\n        self.sample_name = m.group('sample_name')\n        self._read_type = \"illumina\"\n        self._sample_number = int(m.group('sample_number'))\n        self._lane_number = int(m.group('lane_number'))\n        self._read_number = int(m.group('read_number'))\n        self._index_number = int(m.group('index_number'))\n    elif m := _SHORT_READ_REGEX.match(self.id):\n        self.sample_name = m.group('sample_name')\n        self._read_type = \"short\"\n        self._read_number = int(m.group('read_number'))\n</code></pre>"},{"location":"reference/eris/io/#eris.io.ReadSet","title":"<code>ReadSet</code>","text":"<p>Whilst still representing genomes, these are different from Genome instances as they will not hold sequence information in memory and may consist of multiple files.</p> Source code in <code>eris/io.py</code> <pre><code>class ReadSet:\n    \"\"\"\n    Whilst still representing genomes, these are different from Genome instances as they will not hold\n    sequence information in memory and may consist of multiple files.\n    \"\"\"\n    def __init__(self, *files: Union[str, Path, ReadFile], id_: str = None):\n        self.id = id_\n        self._files = []\n        read_types = set()\n        for file in files:\n            if not isinstance(file, ReadFile):\n                file = ReadFile(file)\n            if self.id is None:\n                self.id = file.sample_name\n            else:\n                if self.id != file.sample_name:\n                    raise ReadSetError(f'{file.id} sample name {file.sample_name} does not match ReadSet {self.id}')\n            self._files.append(file)\n            read_types.add(file.read_type)\n        if len(read_types) &gt; 1:\n            raise ReadSetError(f'Hybrid read set {self.id} not yet supported')\n        else:\n            self._set_type = read_types.pop()\n\n    @property\n    def set_type(self):\n        return self._set_type\n\n    def __iter__(self):\n        return iter(self._files)\n\n    def __repr__(self):\n        return self.id\n\n    def __str__(self):\n        return ' '.join([str(read) for read in self._files])\n\n    def __len__(self):\n        return len(self._files)\n</code></pre>"},{"location":"reference/eris/io/#eris.io.SeqFile","title":"<code>SeqFile</code>","text":"<p>Class for handling a (possibly compressed) file or stream of biological formats.</p> <p>:param file: Path to file (str/Path) or an IO stream (binary or text). :param format_: Format of the file. If None, the format will be guessed from the                 filename extension or the stream content. :return: A SeqFile instance</p> Source code in <code>eris/io.py</code> <pre><code>class SeqFile:\n    \"\"\"\n    Class for handling a (possibly compressed) file or stream of biological formats.\n\n    :param file: Path to file (str/Path) or an IO stream (binary or text).\n    :param format_: Format of the file. If None, the format will be guessed from the\n                    filename extension or the stream content.\n    :return: A SeqFile instance\n    \"\"\"\n    def __init__(self, file: Union[str, Path, IO], format_: _SUPPORTED_FORMATS = None, temp_prefix='seqfile_'):\n        self.id: str = \"unknown\"\n        self.path: Union[Path, None] = None\n        self.format: Union[str, None] = format_\n        self._handle: Union[IO, None] = None\n        self._from_stream: bool = False\n        self._open_func: Union[None, Callable] = None\n\n        if file in {'-', 'stdin'}:  # Handle stdin symbol, the rest of the logic should deal with the stream\n            file = stdin\n\n        if hasattr(file, 'read') and not isinstance(file, (str, Path)):  # --- Handle IO Stream Input ---\n            if not isinstance(file, (BufferedIOBase, RawIOBase)):\n                if buffer := getattr(file, 'buffer', None):\n                    file = buffer\n                else:\n                    raise SeqFileError(\"Input stream is not binary and lacks an accessible binary buffer (.buffer).\")\n\n            # The existing, clever solution: dump the stream to a temp file to make it seekable.\n            with NamedTemporaryFile(prefix=temp_prefix, suffix='.tmp', delete=False, mode='wb') as temp_f_handle:\n                copyfileobj(file, temp_f_handle)\n                self.path = Path(temp_f_handle.name)\n                self.id = self.path.stem\n                self._from_stream = True\n\n            # Now, we can safely open and guess from the temp file.\n            if self.format is None:\n                try:  # xopen handles decompression automatically based on magic numbers\n                    with xopen(self.path, mode='rt') as f:\n                        self.format = _guess_format_from_handle(f)\n                except Exception as e:  # Clean up the temp file on failure\n                    self.path.unlink(missing_ok=True)\n                    raise e\n\n            # The suffix for the temp file doesn't matter since we use xopen's 'magic' method\n            self._open_func = partial(xopen, self.path, method='magic', mode='rt')\n\n        elif isinstance(file, (str, Path)):  # --- Handle File Path Input ---\n            self.path = file if isinstance(file, Path) else Path(file)\n            if m := _SEQUENCE_FILE_REGEX.search(self.path.name):\n                self.id = self.path.name.rstrip(m.group())  # If format is not provided, guess from extension.\n                self.format = format_ or next(fmt for fmt in get_args(_SUPPORTED_FORMATS) if m[fmt])\n                self._open_func = partial(xopen, self.path, method=m['compression'] or 'uncompressed', mode='rt')\n            else:  # If no valid extension, try guessing from content\n                if self.format is None:\n                    try:\n                        with xopen(self.path, mode='rt') as f:\n                            self.format = _guess_format_from_handle(f)\n                        self._open_func = partial(xopen, self.path, method='magic', mode='rt')\n                    except Exception as e:\n                         raise SeqFileError(f'Unsupported file extension and could not guess format for: {self.path.name}') from e\n                else: # Format was provided, but extension is weird. Trust the user.\n                    self._open_func = partial(xopen, self.path, method='magic', mode='rt')\n        else:\n            raise TypeError(f\"Input must be a file path (str or Path) or an IO stream, not {type(file)}\")\n\n    def __repr__(self):\n        return f'SeqFile({self.id}, format={self.format})'\n\n    def __str__(self):\n        return self.id\n\n    def __enter__(self):\n        self._ensure_handle_open()  # Open the handle when entering context, using the appropriate _open_func\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.close()  # Ensure the primary handle (_handle) is closed\n        if self._from_stream:  # Clean up the temporary file *only* if it was created from a stream\n            try:  # Use missing_ok=True for robustness against race conditions etc.\n                self.path.unlink(missing_ok=True)\n            except OSError as e:  # Log or warn about failure to delete temp file\n                 warn(f\"Could not delete temporary file {self.path}: {e}\", SeqFileWarning)\n\n    def __del__(self):  # Minimal cleanup: try to close the handle and delete temp file if applicable\n        self.close()  # Subject to usual __del__ caveats (timing, interpreter state)\n        if getattr(self, '_from_stream', False) and hasattr(self, 'path'):\n             try:  # Avoid print/warn in __del__ if possible, or use sys.stderr\n                 self.path.unlink(missing_ok=True)\n             except Exception:\n                 pass # Ignore errors in __del__\n\n    def _ensure_handle_open(self):\n        \"\"\"Internal helper to open/reopen the file via _open_func.\"\"\"\n        if self._handle is None or self._handle.closed:\n             self.close()  # Close any potentially lingering closed handle first\n             self._handle = self._open_func()  # Open fresh using the configured function (xopen for paths/streams)\n\n    def close(self):\n        \"\"\"Closes the associated file handle (_handle), if open.\"\"\"\n        if self._handle and not self._handle.closed:\n            try:\n                self._handle.close()\n            except Exception as e:\n                 pass   # Ignore potential errors during close, especially in __del__ context\n        self._handle = None  # Mark as closed\n\n    def read(self) -&gt; str:\n        \"\"\"Reads the entire content of the file (decompressed).\"\"\"\n        self._ensure_handle_open()  # Ensure we have a fresh handle from the start\n        content = self._handle.read()  # Read from the current handle (which was just opened/rewound)\n        # Close handle after full read? Optional, depends on expected usage.\n        # self.close()\n        return content\n\n    def rewind(self):\n        \"\"\"Resets the file to be read from the beginning.\"\"\"\n        # The simplest way to rewind when using xopen dynamically is to close\n        # the current handle and let _ensure_handle_open get a new one.\n        self.close()  # Next call to read() or __iter__() will automatically reopen via _ensure_handle_open()\n\n    def __iter__(self) -&gt; Generator[Union['Record', 'Edge', 'Feature'], None, None]:\n        \"\"\"Returns an iterator (generator) over records in the file.\"\"\"\n        self._ensure_handle_open() # Ensure handle is open/reopened\n        if not self.format:\n             raise SeqFileError(\"Cannot parse file: format is unknown.\")\n        yield from parse(self._handle, self.format)\n        # Note: Iteration consumes the handle. Re-iteration requires rewind()/re-opening.\n\n    def peek(self) -&gt; str:\n        \"\"\"Returns the first line and resets to the beginning.\"\"\"\n        self._ensure_handle_open()\n        first_line = self._handle.readline()\n        self.rewind()  # Rewind by closing and letting the next operation reopen\n        return first_line\n</code></pre>"},{"location":"reference/eris/io/#eris.io.SeqFile.__iter__","title":"<code>__iter__()</code>","text":"<p>Returns an iterator (generator) over records in the file.</p> Source code in <code>eris/io.py</code> <pre><code>def __iter__(self) -&gt; Generator[Union['Record', 'Edge', 'Feature'], None, None]:\n    \"\"\"Returns an iterator (generator) over records in the file.\"\"\"\n    self._ensure_handle_open() # Ensure handle is open/reopened\n    if not self.format:\n         raise SeqFileError(\"Cannot parse file: format is unknown.\")\n    yield from parse(self._handle, self.format)\n</code></pre>"},{"location":"reference/eris/io/#eris.io.SeqFile.close","title":"<code>close()</code>","text":"<p>Closes the associated file handle (_handle), if open.</p> Source code in <code>eris/io.py</code> <pre><code>def close(self):\n    \"\"\"Closes the associated file handle (_handle), if open.\"\"\"\n    if self._handle and not self._handle.closed:\n        try:\n            self._handle.close()\n        except Exception as e:\n             pass   # Ignore potential errors during close, especially in __del__ context\n    self._handle = None  # Mark as closed\n</code></pre>"},{"location":"reference/eris/io/#eris.io.SeqFile.peek","title":"<code>peek()</code>","text":"<p>Returns the first line and resets to the beginning.</p> Source code in <code>eris/io.py</code> <pre><code>def peek(self) -&gt; str:\n    \"\"\"Returns the first line and resets to the beginning.\"\"\"\n    self._ensure_handle_open()\n    first_line = self._handle.readline()\n    self.rewind()  # Rewind by closing and letting the next operation reopen\n    return first_line\n</code></pre>"},{"location":"reference/eris/io/#eris.io.SeqFile.read","title":"<code>read()</code>","text":"<p>Reads the entire content of the file (decompressed).</p> Source code in <code>eris/io.py</code> <pre><code>def read(self) -&gt; str:\n    \"\"\"Reads the entire content of the file (decompressed).\"\"\"\n    self._ensure_handle_open()  # Ensure we have a fresh handle from the start\n    content = self._handle.read()  # Read from the current handle (which was just opened/rewound)\n    # Close handle after full read? Optional, depends on expected usage.\n    # self.close()\n    return content\n</code></pre>"},{"location":"reference/eris/io/#eris.io.SeqFile.rewind","title":"<code>rewind()</code>","text":"<p>Resets the file to be read from the beginning.</p> Source code in <code>eris/io.py</code> <pre><code>def rewind(self):\n    \"\"\"Resets the file to be read from the beginning.\"\"\"\n    # The simplest way to rewind when using xopen dynamically is to close\n    # the current handle and let _ensure_handle_open get a new one.\n    self.close()  # Next call to read() or __iter__() will automatically reopen via _ensure_handle_open()\n</code></pre>"},{"location":"reference/eris/io/#eris.io.group_reads","title":"<code>group_reads(reads)</code>","text":"<p>Helper function, mostly for CLI, for grouping together read files for the same sample. Useful for grouping paired-end or hybrid (long + short) readsets.</p> Notes <ul> <li>Whilst this function can accept input streams, everything is coerced into ReadFile instances and will be   written to disk, so this should be taken into consideration before processing many streams.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>reads</code> <code>Iterable[Union[Path, str, IO, ReadFile]]</code> <p>An iterable of files as strings or Path objects, ReadFile or IO streams.</p> required <p>Yields:</p> Type Description <code>ReadSet</code> <p>ReadSet instances</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; for readset in group_reads(Path('reads').iterdir()):\n&gt;&gt;&gt;     print(f'{readset:fasta}', end='')\n</code></pre> Source code in <code>eris/io.py</code> <pre><code>def group_reads(reads: Iterable[Union[Path, str, IO, ReadFile]]) -&gt; Generator[ReadSet, None, None]:\n    \"\"\"\n    Helper function, mostly for CLI, for grouping together read files for the same sample.\n    Useful for grouping paired-end or hybrid (long + short) readsets.\n\n    Notes:\n        - Whilst this function can accept input streams, everything is coerced into ReadFile instances and will be\n          written to disk, so this should be taken into consideration before processing many streams.\n\n    Arguments:\n        reads: An iterable of files as strings or Path objects, ReadFile or IO streams.\n\n    Yields:\n        ReadSet instances\n\n    Examples:\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; for readset in group_reads(Path('reads').iterdir()):\n        &gt;&gt;&gt;     print(f'{readset:fasta}', end='')\n\n    \"\"\"\n    for sample_name, files in grouper(((ReadFile(i) if not isinstance(i, ReadFile) else i) for i in reads), 'sample_name'):\n        yield ReadSet(*files, id_=sample_name)\n</code></pre>"},{"location":"reference/eris/io/#eris.io.parse","title":"<code>parse(handle, format_='guess', *args, **kwargs)</code>","text":"<p>Simple parser for fasta, gfa and genbank formats, similar to Biopython https://biopython.org/docs/latest/api/Bio.SeqIO.html#Bio.SeqIO.parse</p> <p>Parameters:</p> Name Type Description Default <code>handle</code> <code>TextIO</code> <p>A file handle opened in text-mode / text stream</p> required <code>format_</code> <code>_SUPPORTED_FORMATS</code> <p>The format of the file; must be one of the supported formats or guess by default</p> <code>'guess'</code> <p>Yields:</p> Type Description <code>Union[Record, Edge, Feature]</code> <p>Record, Feature or Edge objects</p> Source code in <code>eris/io.py</code> <pre><code>def parse(handle: TextIO, format_: _SUPPORTED_FORMATS = 'guess', *args, **kwargs) -&gt; Generator[Union[Record, Edge, Feature], None, None]:\n    \"\"\"\n    Simple parser for fasta, gfa and genbank formats,\n    similar to Biopython &lt;https://biopython.org/docs/latest/api/Bio.SeqIO.html#Bio.SeqIO.parse&gt;\n\n    Parameters:\n        handle: A file handle opened in text-mode / text stream\n        format_: The format of the file; must be one of the supported formats or guess by default\n\n    Yields:\n        Record, Feature or Edge objects\n    \"\"\"\n    if format_ == 'guess':\n        if m := _SEQUENCE_FILE_REGEX.search(handle.name):\n            format_ = next(fmt for fmt in get_args(_SUPPORTED_FORMATS) if m[fmt])\n        else:\n            raise SeqFileError(f'Unsupported SeqFile format or extension: {handle.name}')\n    if parser := {'fasta': _parse_fasta, 'gfa': _parse_gfa, 'genbank': _parse_genbank, 'fastq': _parse_fastq,\n                  'gff': _parse_gff, 'bed': _parse_bed}.get(format_):\n        yield from parser(handle, *args, **kwargs)\n    else:\n        raise NotImplementedError(f'Format \"{format_}\" not supported')\n</code></pre>"},{"location":"reference/eris/mapper/","title":"eris.mapper","text":"<p>Module for running the map pipelines on bacterial read sets.</p>"},{"location":"reference/eris/pan/","title":"eris.pan","text":"<p>Module for running the pangenome pipeline on bacterial pangenome graphs.</p>"},{"location":"reference/eris/scan/","title":"eris.scan","text":"<p>Module for running the scan pipeline on bacterial genomes.</p>"},{"location":"reference/eris/scan/#eris.scan.Scanner","title":"<code>Scanner</code>","text":"<p>A class that runs the eris scan pipeline on bacterial genomes. The scan pipeline takes a single bacterial genome, predicts ORFs if necessary, and uses Minimap2 to find IS elements with nucleotide-nucleotide alignment against contigs. Then, ORFs belonging to- or flanked by- the IS elements are identified (including potential graph traversal), and are returned in a result object for later reporting.</p> <p>Attributes:</p> Name Type Description <code>db</code> <code>Database</code> <p>The ISFinder sequence eris.Database object.</p> <code>align_config</code> <code>Minimap2AlignConfig</code> <p>Minimap2 alignment configuration.</p> <code>index_config</code> <code>Minimap2IndexConfig</code> <p>Minimap2 index configuration.</p> <code>gene_finder_config</code> <code>GeneFinderConfig</code> <p>Configuration for the pyrodigal.GeneFinder instance if needed.</p> <code>min_overlap</code> <code>float</code> <p>Minimum %overlap for a CDS to be part of an element.</p> <code>min_proximity</code> <code>int</code> <p>Minimum distance in bp for an element to have an effect on a CDS.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from eris.scanner import Scanner\n... from pathlib import Path\n... with Scanner() as scanner:\n...     results = list(scanner.scan(*Path.iterdir('genomes/')))\n</code></pre> Source code in <code>eris/scan.py</code> <pre><code>class Scanner:\n    \"\"\"\n    A class that runs the eris scan pipeline on bacterial genomes. The scan pipeline takes a single bacterial genome,\n    predicts ORFs if necessary, and uses Minimap2 to find IS elements with nucleotide-nucleotide alignment against\n    contigs. Then, ORFs belonging to- or flanked by- the IS elements are identified\n    (including potential graph traversal), and are returned in a result object for later reporting.\n\n    Attributes:\n        db (Database): The ISFinder sequence eris.Database object.\n        align_config (Minimap2AlignConfig): Minimap2 alignment configuration.\n        index_config (Minimap2IndexConfig): Minimap2 index configuration.\n        gene_finder_config (GeneFinderConfig): Configuration for the pyrodigal.GeneFinder instance if needed.\n        min_overlap (float): Minimum %overlap for a CDS to be part of an element.\n        min_proximity (int): Minimum distance in bp for an element to have an effect on a CDS.\n\n    Examples:\n        &gt;&gt;&gt; from eris.scanner import Scanner\n        ... from pathlib import Path\n        ... with Scanner() as scanner:\n        ...     results = list(scanner.scan(*Path.iterdir('genomes/')))\n    \"\"\"\n    def __init__(self, align_config: Minimap2AlignConfig = None, index_config: Minimap2IndexConfig = None,\n                 gene_finder_config: GeneFinderConfig = None, pool: 'Executor' = None, min_overlap: float = 0.8,\n                 min_proximity: int = 150):\n        self.db: Database = Database()\n        self.align_config: Minimap2AlignConfig = align_config or Minimap2AlignConfig(c=True)\n        self.index_config: Minimap2IndexConfig = index_config or Minimap2IndexConfig()\n        self.gene_finder_config: GeneFinderConfig = gene_finder_config or GeneFinderConfig()\n        self.min_overlap: float = min_overlap\n        self.min_proximity: int = min_proximity\n        self._pool: 'Executor' = pool  # Only init the pool if we need it for the gene finder\n        self._gene_finder: 'pyrodigal.GeneFinder' = None\n\n    @property\n    @require('pyrodigal')\n    def gene_finder(self):\n        if not self._gene_finder:\n            from pyrodigal import GeneFinder\n            self._gene_finder = GeneFinder(**asdict(self.gene_finder_config))\n        return self._gene_finder\n\n    def cleanup(self):\n        self._gene_finder = None\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.cleanup()\n\n    def __del__(self):\n        self.cleanup()\n\n    def __call__(self, *args, **kwargs):\n        return self._pipeline(*args, **kwargs)\n\n    def scan(self, *genomes: Union[str, Path, IO, SeqFile, Genome]) -&gt; Generator[ScannerResult, None, None]:\n        \"\"\"\n        Runs the pipeline on input genomes\n\n        Arguments:\n            genomes: Input genomes to scan, can be strings or Paths to files, SeqFile instances or Genome instances\n\n        Yields:\n            ScannerResult instances for each genome processed or None\n        \"\"\"\n        yield from map(self._pipeline, genomes)\n\n    def _pipeline(self, genome: Union[str, Path, IO, SeqFile, Genome]) -&gt; Union[ScannerResult, None]:\n        if not isinstance(genome, Genome):\n            try:\n                genome = Genome.from_file(genome)\n            except Exception as e:\n                raise ScannerError(f\"Could not parse {genome} as Genome\") from e\n\n        contigs_with_is: list[Record] = []\n        with Minimap2(targets=genome, index_config=self.index_config) as aligner:  # Align IS to contigs\n            for contig, alignments in grouper(aligner.align(self.db, config=self.align_config), 'target'):\n                (contig := genome[contig]).add_features(*(i.as_feature('mobile_element') for i in cull_all(alignments)))\n                contigs_with_is.append(contig)  # Add contig name to list, also indicator that we have alignments\n\n        if not contigs_with_is:  # No alignments found, warn and exit early\n            return warn('No alignments found', ScannerWarning)\n\n        if not genome.is_annotated:  # Get ORFs if necessary, only do this if we have alignments to exit early\n            if self.gene_finder is None:\n                raise ScannerError(f\"Could not predict ORFs in {genome}; is Pyrodigal installed?\")\n            genes = {gene.id: gene for gene in genome.find_genes(self.gene_finder, self._pool)}\n        else:  # Get the existing annotations from the genome, TODO: Should we support other feature types?\n            genes = {gene.id: gene for contig in genome.contigs.values() for gene in contig.features if gene.kind == 'CDS'}\n\n        graph = genome.as_feature_graph()  # Get the gene graph for traversing connected genes\n        result = ScannerResult(genome.id)  # Init the result container\n\n        for contig in contigs_with_is:  # Iterate over contigs with IS element alignments\n            for element in filter(lambda i: i.kind == 'mobile_element', contig):  # type: Feature\n\n                # This block performs a graph traversal (BFS) starting from the neighbors of the IS element\n                # to find all genes that are part of the IS element vs. those that are merely flanked by it.\n                element.extract(contig, store_seq=True)  # Extract and store nucleotide sequence of element\n                element.qualifiers += self.db[element['name']].qualifiers  # Pull over the qualifiers from the database\n                element.qualifiers.append(Qualifier('mobile_element_type', 'insertion sequence'))\n                result.features.append(element)  # Add element to result features\n                result.contexts[element.id] = Context(element.id)\n\n                promoter = None\n                for promoter in element.find_promoters(contig):\n                    result.features.append(promoter)  # Add element promoter to result features\n                    result.contexts[promoter.id] = Context(element.id, location='inside')  # Add promoter to result context\n\n                # A queue for edges to visit. Start with the direct neighbors of the IS element.\n                # We use a deque for efficient appends and pops from the left (FIFO) and  a set to keep track of\n                # edges we've already processed to avoid cycles and redundant work.\n                processed_edges = set(edges_to_visit := deque(graph.get_neighbors(element.id)))\n\n                while edges_to_visit:\n                    edge = edges_to_visit.popleft()\n                    if not (gene := genes.get(edge.to)) or gene.id in result.contexts:\n                        continue  # Use result to check processed genes\n\n                    result.edges.append(edge)  # Add edge to result for gfa output\n                    result.features.append(gene)  # Add gene to result features\n                    gene_context = Context(\n                        element.id, location='flanking',\n                        strand='same strand' if element.location.strand == gene.location.strand else 'opposite strand'\n                    )\n                    translation = gene.translate(parent=genome[gene.location.parent_id])  # Extract translation\n                    # Calculate the context of the gene relative to the element.\n                    # A gene can only be part of the IS element if it's on the same contig.\n                    # Otherwise, it's a flanking gene by definition.\n                    # TODO: Add stitching logic for elements that span multiple contigs\n                    if gene.location.parent_id == element.location.parent_id:  # On the same contig\n                        if element.overlap(gene) / len(gene) &gt;= self.min_overlap:  # This gene is part of the IS element\n                            gene_context.location = 'inside'  # Since it's part of the IS, we need to explore its\n                            # neighbors as well to find the full extent of the element.\n                            for next_edge in graph.get_neighbors(gene.id):\n                                if next_edge not in processed_edges:\n                                    processed_edges.add(next_edge)\n                                    edges_to_visit.append(next_edge)\n\n                        else:  # Non-overlapping gene on same contig\n                            if element.location.start &gt; gene.location.start: # Element comes after gene\n                                gene_context.distance = element.location.start - gene.location.end\n                                gene_context.location = 'upstream' if element.location.strand == 1 else 'downstream'\n                            else:\n                                gene_context.distance = gene.location.start - element.location.end\n                                gene_context.location = 'downstream' if element.location.strand == 1 else 'upstream'\n\n                            if gene_context.distance &lt;= self.min_proximity:  # Predict effects\n                                if promoter and gene_context.location == 'downstream' and gene_context.strand == 'same strand':\n                                    gene_context.effect = 'upregulated'\n                                elif not gene.partial() and (translation[0] not in {'M', 'V'} or translation[-1] != '*'):\n                                    gene_context.effect = 'disrupted'\n\n                    result.contexts[gene.id] = gene_context\n\n        result.features.sort(key=attrgetter('location.parent_id', 'location.start'))\n        return result\n</code></pre>"},{"location":"reference/eris/scan/#eris.scan.Scanner.scan","title":"<code>scan(*genomes)</code>","text":"<p>Runs the pipeline on input genomes</p> <p>Parameters:</p> Name Type Description Default <code>genomes</code> <code>Union[str, Path, IO, SeqFile, Genome]</code> <p>Input genomes to scan, can be strings or Paths to files, SeqFile instances or Genome instances</p> <code>()</code> <p>Yields:</p> Type Description <code>ScannerResult</code> <p>ScannerResult instances for each genome processed or None</p> Source code in <code>eris/scan.py</code> <pre><code>def scan(self, *genomes: Union[str, Path, IO, SeqFile, Genome]) -&gt; Generator[ScannerResult, None, None]:\n    \"\"\"\n    Runs the pipeline on input genomes\n\n    Arguments:\n        genomes: Input genomes to scan, can be strings or Paths to files, SeqFile instances or Genome instances\n\n    Yields:\n        ScannerResult instances for each genome processed or None\n    \"\"\"\n    yield from map(self._pipeline, genomes)\n</code></pre>"},{"location":"reference/eris/seq/","title":"eris.seq","text":"<p>Module containing data structures for representing bacterial sequence components, similar to Biopython.</p>"},{"location":"reference/eris/seq/#eris.seq.Feature","title":"<code>Feature</code>","text":"<p>               Bases: <code>HasLocation</code></p> <p>Represents a feature on a sequence, consisting of a location. Unlike the BioPython Features, these Features may store their sequences as an attribute, but may not always.</p> <p>Attributes:</p> Name Type Description <code>id</code> <p>The unique identifier for the feature.</p> <code>kind</code> <p>The type of feature (e.g., gene, CDS, rRNA).</p> <code>seq</code> <p>The sequence of the feature (optional).</p> <code>qualifiers</code> <p>A list of Qualifier objects providing additional information about the feature.</p> Source code in <code>eris/seq.py</code> <pre><code>class Feature(HasLocation):\n    \"\"\"\n    Represents a feature on a sequence, consisting of a location.\n    Unlike the BioPython Features, these Features may store their sequences as an attribute, but may not always.\n\n    Attributes:\n        id: The unique identifier for the feature.\n        kind: The type of feature (e.g., gene, CDS, rRNA).\n        seq: The sequence of the feature (optional).\n        qualifiers: A list of Qualifier objects providing additional information about the feature.\n    \"\"\"\n\n    def __init__(self, location: Location, id_: str = None, kind: str = 'misc_feature',\n                 seq: Union[Seq, str] = None, qualifiers: list[Qualifier] = None):\n        super().__init__(location)\n        self.id = id_ or str(uuid4())\n        self.kind = kind\n        self.seq = (seq if isinstance(seq, Seq) else Seq(seq)) if seq else None\n        self.qualifiers = qualifiers or []\n\n    def __repr__(self):\n        return f\"{self.kind}({self.id} {self.location})\"\n\n    def __str__(self):\n        return self.id\n\n    def __hash__(self) -&gt; int:\n        return hash(self.id)\n\n    def __eq__(self, other):\n        if isinstance(other, 'Feature'):\n            return self.id == other.id\n        return False\n\n    def __getitem__(self, item: str) -&gt; Union[Any, None]:\n        \"\"\"\n        Quick method of getting a qualifier by key using next()\n        Warning:\n            This will only return the first instance, which in most cases is fine\n        \"\"\"\n        if not isinstance(item, str):\n            raise TypeError(item)\n        return next((v for k, v in self.qualifiers if k == item), None)\n\n    def __format__(self, __format_spec: Literal['fasta', 'ffn', 'fna', 'faa', 'bed', 'tsv'] = ''):\n        if __format_spec == '':\n            return self.__str__()\n        elif __format_spec in {'fasta', 'ffn', 'fna'}:\n            if self.seq is None:\n                raise AttributeError(f'No seq extracted for {self=}')\n            else:\n                return f\"&gt;{self.id}\\n{self.seq}\\n\"\n        elif __format_spec == 'faa':\n            return f\"&gt;{self.id}\\n{self.translate()}\\n\"\n        elif __format_spec == 'bed':\n            return (f'{self.location.start}\\t{self.location.end}\\t{self.id}\\t'\n                    f'{next((v for k, v in self.qualifiers if k == \"score\"), 0)}\\t'\n                    f'{\"+\" if self.location.strand == 1 else \"-\"}\\n')\n        elif __format_spec == 'tsv':\n            return f'{self}\\t{self.kind}\\t{self.location:tsv}'\n            # return f'{self}\\t{self.location:tsv}'\n        else:\n            raise NotImplementedError(f'Format \"{__format_spec}\" not supported')\n\n    @classmethod\n    def random(cls, parent: Record, id_: str = None, rng: Random = None, min_len: int = 1,\n               max_len: int = 10000, min_start: int = 0, max_start: int = 1000000):\n        location = Location.random(rng, min_len=min_len, max_len=min(max_len, len(parent)), min_start=min_start,\n                                   max_start=min(max_start, len(parent) - max_len))\n        location.parent_id = parent.id\n        feature = cls(location, id_ or str(uuid4()), 'CDS')\n        feature.extract(parent, store_seq=True)\n        return feature\n\n    def translate(\n            self, to_stop: bool = True, stop_symbol: str = \"*\", frame: Literal[0, 1, 2] = 0, gap_character: str = None,\n            store_translation: bool = True,\n            parent: Union[Union[Seq, Record, 'Feature'], dict[str, Union[Seq, Record, 'Feature']]] = None,\n            store_seq: bool = False\n    ) -&gt; Seq:\n        \"\"\"\n        Translates the feature to amino acid if it is a nucleotide sequence\n        :param to_stop: Boolean to stop translation at the first stop codon\n        :param stop_symbol: Character to resemble the stop codon\n        :param frame: Zero-based frame to begin translation from\n        :param gap_character: The gap character if performing a gapped-translation\n        :param store_translation: Boolean to store the translation in the feature\n        :param parent: Parent object (``Seq``, ``Record``, ``Feature``) or dictionary of parent objects\n        :param store_seq: Boolean to store the translated sequence in the feature\n        :return: Translated sequence\n        \"\"\"\n        if not (translation := next((v for k, v in self.qualifiers if k == 'translation'), None)):\n            if self.seq is None:\n                if parent is None:\n                    raise AttributeError(f'Cannot translate feature \"{self.id}\" without a stored sequence or parent to '\n                                         f'extract from')\n                else:\n                    translation = self.extract(parent, store_seq).translate(to_stop, stop_symbol, frame, gap_character)\n            else:\n                translation = self.seq.translate(to_stop, stop_symbol, frame, gap_character)\n            if store_translation:\n                self.qualifiers.append(Qualifier('translation', translation))\n        return translation\n\n    def GC(self) -&gt; float:\n        \"\"\"Returns the GC content of the feature\"\"\"\n        if not (gc := next((v for k, v in self.qualifiers if k == 'GC'), None)):\n            if not self.seq:\n                raise AttributeError(f'No seq extracted for {self=}')\n            gc = self.seq.GC()\n            self.qualifiers.append(Qualifier('GC', gc))\n        return gc\n\n    def extract(self, parent: Union[Union[Seq, Record, 'Feature'], dict[str, Union[Seq, Record, 'Feature']]],\n                store_seq: bool = False) -&gt; 'Seq':\n        seq = self.location.extract(parent)\n        if store_seq:\n            self.seq = seq\n        return seq\n\n    def shift(self, by: int) -&gt; 'Feature':\n        return Feature(self.location.shift(by), self.id, self.kind, None, self.qualifiers)\n\n    def reverse_complement(self, parent_length: int) -&gt; 'Feature':\n        return Feature(\n            self.location.reverse_complement(parent_length), self.id, self.kind,\n            self.seq.reverse_complement() if self.seq else None, self.qualifiers\n        )\n\n    def find_promoters(self, parent: Union[Union[Seq, Record, 'Feature']]) -&gt; Generator['Feature', None, None]:\n        \"\"\"\n        Finds promoters within the feature's sequence.\n\n        :param parent: Parent object (``Seq``, ``Record``, ``Feature``)\n        :return: Generator of Feature objects representing the promoters\n        \"\"\"\n        for n, match in enumerate(_PROMOTER_REGEX.finditer(str(self.seq)), start=1):\n            yield Feature(\n                Location(match.start() + self.location.start, match.end() + self.location.start, self.location.strand,\n                         parent_id=self.location.parent_id),f\"{self.id}_promoter_{n}\", 'regulatory',\n                         qualifiers=[Qualifier('regulatory_class', 'promoter')])\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Feature.GC","title":"<code>GC()</code>","text":"<p>Returns the GC content of the feature</p> Source code in <code>eris/seq.py</code> <pre><code>def GC(self) -&gt; float:\n    \"\"\"Returns the GC content of the feature\"\"\"\n    if not (gc := next((v for k, v in self.qualifiers if k == 'GC'), None)):\n        if not self.seq:\n            raise AttributeError(f'No seq extracted for {self=}')\n        gc = self.seq.GC()\n        self.qualifiers.append(Qualifier('GC', gc))\n    return gc\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Feature.__getitem__","title":"<code>__getitem__(item)</code>","text":"<p>Quick method of getting a qualifier by key using next() Warning:     This will only return the first instance, which in most cases is fine</p> Source code in <code>eris/seq.py</code> <pre><code>def __getitem__(self, item: str) -&gt; Union[Any, None]:\n    \"\"\"\n    Quick method of getting a qualifier by key using next()\n    Warning:\n        This will only return the first instance, which in most cases is fine\n    \"\"\"\n    if not isinstance(item, str):\n        raise TypeError(item)\n    return next((v for k, v in self.qualifiers if k == item), None)\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Feature.find_promoters","title":"<code>find_promoters(parent)</code>","text":"<p>Finds promoters within the feature's sequence.</p> <p>:param parent: Parent object (<code>Seq</code>, <code>Record</code>, <code>Feature</code>) :return: Generator of Feature objects representing the promoters</p> Source code in <code>eris/seq.py</code> <pre><code>def find_promoters(self, parent: Union[Union[Seq, Record, 'Feature']]) -&gt; Generator['Feature', None, None]:\n    \"\"\"\n    Finds promoters within the feature's sequence.\n\n    :param parent: Parent object (``Seq``, ``Record``, ``Feature``)\n    :return: Generator of Feature objects representing the promoters\n    \"\"\"\n    for n, match in enumerate(_PROMOTER_REGEX.finditer(str(self.seq)), start=1):\n        yield Feature(\n            Location(match.start() + self.location.start, match.end() + self.location.start, self.location.strand,\n                     parent_id=self.location.parent_id),f\"{self.id}_promoter_{n}\", 'regulatory',\n                     qualifiers=[Qualifier('regulatory_class', 'promoter')])\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Feature.translate","title":"<code>translate(to_stop=True, stop_symbol='*', frame=0, gap_character=None, store_translation=True, parent=None, store_seq=False)</code>","text":"<p>Translates the feature to amino acid if it is a nucleotide sequence :param to_stop: Boolean to stop translation at the first stop codon :param stop_symbol: Character to resemble the stop codon :param frame: Zero-based frame to begin translation from :param gap_character: The gap character if performing a gapped-translation :param store_translation: Boolean to store the translation in the feature :param parent: Parent object (<code>Seq</code>, <code>Record</code>, <code>Feature</code>) or dictionary of parent objects :param store_seq: Boolean to store the translated sequence in the feature :return: Translated sequence</p> Source code in <code>eris/seq.py</code> <pre><code>def translate(\n        self, to_stop: bool = True, stop_symbol: str = \"*\", frame: Literal[0, 1, 2] = 0, gap_character: str = None,\n        store_translation: bool = True,\n        parent: Union[Union[Seq, Record, 'Feature'], dict[str, Union[Seq, Record, 'Feature']]] = None,\n        store_seq: bool = False\n) -&gt; Seq:\n    \"\"\"\n    Translates the feature to amino acid if it is a nucleotide sequence\n    :param to_stop: Boolean to stop translation at the first stop codon\n    :param stop_symbol: Character to resemble the stop codon\n    :param frame: Zero-based frame to begin translation from\n    :param gap_character: The gap character if performing a gapped-translation\n    :param store_translation: Boolean to store the translation in the feature\n    :param parent: Parent object (``Seq``, ``Record``, ``Feature``) or dictionary of parent objects\n    :param store_seq: Boolean to store the translated sequence in the feature\n    :return: Translated sequence\n    \"\"\"\n    if not (translation := next((v for k, v in self.qualifiers if k == 'translation'), None)):\n        if self.seq is None:\n            if parent is None:\n                raise AttributeError(f'Cannot translate feature \"{self.id}\" without a stored sequence or parent to '\n                                     f'extract from')\n            else:\n                translation = self.extract(parent, store_seq).translate(to_stop, stop_symbol, frame, gap_character)\n        else:\n            translation = self.seq.translate(to_stop, stop_symbol, frame, gap_character)\n        if store_translation:\n            self.qualifiers.append(Qualifier('translation', translation))\n    return translation\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.HasLocation","title":"<code>HasLocation</code>","text":"<p>Base class for objects with a location attribute</p> Source code in <code>eris/seq.py</code> <pre><code>class HasLocation:\n    \"\"\"\n    Base class for objects with a location attribute\n    \"\"\"\n    def __init__(self, location: Location):\n        self.location = location\n\n    def __len__(self) -&gt; int:\n        return self.location.end - self.location.start\n\n    def overlap(self, other: Union[Location, 'HasLocation']) -&gt; int:\n        \"\"\"\n        Returns the length of the overlap between two locations\n        \"\"\"\n        return self.location.overlap(other)\n\n    def __contains__(self, item: Union[Location, 'HasLocation', int, float]) -&gt; bool:\n        \"\"\"\n        Returns True if the object contains the item, False otherwise\n        \"\"\"\n        return self.location.__contains__(item)\n\n    def partial(self) -&gt; bool:\n        return self.location.partial_start or self.location.partial_end\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.HasLocation.__contains__","title":"<code>__contains__(item)</code>","text":"<p>Returns True if the object contains the item, False otherwise</p> Source code in <code>eris/seq.py</code> <pre><code>def __contains__(self, item: Union[Location, 'HasLocation', int, float]) -&gt; bool:\n    \"\"\"\n    Returns True if the object contains the item, False otherwise\n    \"\"\"\n    return self.location.__contains__(item)\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.HasLocation.overlap","title":"<code>overlap(other)</code>","text":"<p>Returns the length of the overlap between two locations</p> Source code in <code>eris/seq.py</code> <pre><code>def overlap(self, other: Union[Location, 'HasLocation']) -&gt; int:\n    \"\"\"\n    Returns the length of the overlap between two locations\n    \"\"\"\n    return self.location.overlap(other)\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Location","title":"<code>Location</code>","text":"<p>Represents a region on a sequence.</p> <p>:param start: Start coordinate (0-based) :param end: End coordinate (0-based) :param strand: Strand (1 or -1) :param partial_start: Boolean indicating if the start is partial :param partial_end: Boolean indicating if the end is partial :param parent_id: Reference sequence name :param joins: List of other locations that are joined to this location</p> Source code in <code>eris/seq.py</code> <pre><code>class Location:\n    \"\"\"\n    Represents a region on a sequence.\n\n    :param start: Start coordinate (0-based)\n    :param end: End coordinate (0-based)\n    :param strand: Strand (1 or -1)\n    :param partial_start: Boolean indicating if the start is partial\n    :param partial_end: Boolean indicating if the end is partial\n    :param parent_id: Reference sequence name\n    :param joins: List of other locations that are joined to this location\n    \"\"\"\n    def __init__(self, start: int, end: int, strand: Literal[1, -1] = 1, partial_start: bool = False,\n                 partial_end: bool = False, parent_id: str = None, *joins: 'Location'):\n        self.start: int = start\n        self.end: int = end\n        self.strand: Literal[1, -1] = strand\n        self.partial_start: bool = partial_start\n        self.partial_end: bool = partial_end\n        self.parent_id: str = parent_id\n        self.joins: list[Location] = list(joins)\n        # TODO: Implement more methods inspired by\n        #  https://github.com/sanger-pathogens/Fastaq/blob/master/src/pyfastaq/intervals.py\n\n    def __hash__(self):\n        return hash((self.start, self.end, self.strand, self.parent_id))\n\n    def __repr__(self):\n        return (f\"{'&gt;' if self.partial_start else ''}{self.start}:{self.end}{'&lt;' if self.partial_end else ''}\"\n                f\"({'+' if self.strand == 1 else '-'})\")\n\n    def __len__(self):\n        return self.end - self.start\n\n    def __iter__(self):\n        return iter((self.start, self.end, self.strand))\n\n    def __contains__(self, item: Union['Location', 'HasLocation', int, float, slice]):\n        if isinstance(item, slice):\n            return self.start &lt;= item.start and self.end &gt;= item.stop\n        elif isinstance(item, (Location, HasLocation)):\n            if isinstance(item, HasLocation):\n                item = item.location\n            return self.start &lt;= item.start and self.end &gt;= item.end\n        elif isinstance(item, (int, float)):\n            return self.start &lt;= item &lt;= self.end\n        else:\n            raise TypeError(item)\n\n    def __add__(self, other: Union['Location', 'HasLocation']) -&gt; 'Location':\n        if isinstance(other, HasLocation):\n            other = other.location\n        if isinstance(other, Location):\n            return Location(min(self.start, other.start), max(self.end, other.end), self.strand)\n        else:\n            raise TypeError(other)\n\n    def __radd__(self, other: Union['Location', 'HasLocation']) -&gt; 'Location':\n        if isinstance(other, HasLocation):\n            other = other.location\n        if isinstance(other, Location):\n            return other.__add__(self)\n        else:\n            raise TypeError(other)\n\n    def __iadd__(self, other: Union['Location', 'HasLocation']):\n        if isinstance(other, HasLocation):\n            other = other.location\n        if isinstance(other, Location):\n            self.start = min(self.start, other.start)\n            self.end = max(self.end, other.end)\n            return self\n        else:\n            raise TypeError(other)\n\n    def __format__(self, __format_spec: Literal['tsv'] = '') -&gt; str:\n        if __format_spec == '':\n            return self.__str__()\n        elif __format_spec == 'tsv':\n            return f'{self.parent_id}\\t{self.start}\\t{self.end}\\t{self.strand}'\n        else:\n            raise NotImplementedError(f'Invalid format: {__format_spec}')\n\n    def overlap(self, other: Union['Location', 'HasLocation']) -&gt; int:\n        \"\"\"\n        Returns the length of the overlap between two locations\n        :param other: Location or HasLocation object\n        \"\"\"\n        if isinstance(other, HasLocation):\n            other = other.location\n        if isinstance(other, Location):\n            return max(0, min(self.end, other.end) - max(self.start, other.start))\n        else:\n            raise TypeError(other)\n\n    def extract(self, parent: Union[Union['Seq', 'Record', 'Feature'], dict[str, Union['Seq', 'Record', 'Feature']]]) -&gt; 'Seq':\n        \"\"\"\n        Extracts a sequence from a parent object based on the location.\n\n        :param parent: Parent object (``Seq``, ``Record``, ``Feature``) or dictionary of parent objects\n        :return: Seq object\n        \"\"\"\n        new_seq = []\n        if isinstance(parent, dict):\n            if not (ref := parent.get(self.parent_id)):\n                raise LocationError(f'{self.parent_id=} not in parent dictionary')\n            new_seq.append(ref.seq[self] if not isinstance(ref, Seq) else ref[self])\n        else:\n            if self.parent_id and not isinstance(parent, Seq) and parent.id != self.parent_id:\n                raise LocationError(f'{self.parent_id=} does not match {parent.id=}')\n            new_seq.append(parent.seq[self] if not isinstance(parent, Seq) else parent[self])\n        if self.joins:\n            new_seq += (i.extract(parent) for i in self.joins)\n        if len(alphabet := {i.alphabet for i in new_seq}) &gt; 1:\n            raise LocationError('Cannot extract sequence from mixed alphabet types')\n        return Seq(''.join(map(str, new_seq)), alphabet.pop())\n\n    def shift(self, by: int):\n        return Location(self.start + by, self.end + by, self.strand)\n\n    def reverse_complement(self, parent_length: int) -&gt; 'Location':\n        return Location(\n            parent_length - self.end, parent_length - self.start, -self.strand,\n            self.partial_end, self.partial_start, self.parent_id\n        )\n\n    @classmethod\n    def random(cls, rng: Random = None, length: int = None, min_len: int = 1, max_len: int = 10000,\n               min_start: int = 0, max_start: int = 1000000):\n        if rng is None:\n            rng = RESOURCES.rng\n        if not length:\n            length = rng.randint(min_len, max_len)\n        start = rng.randint(min_start, max_start - length)\n        return cls(start, start + length, rng.choice([1, -1]))\n\n    def _get_points(self, max_head_length: float, shape: Literal['arrow', 'box'] = 'arrow',\n                    arrow_shaft_width: float = 0.4, head_width_ratio: float = 1.5, head_length_ratio: float = 0.2):\n        \"\"\"\n        Generates a set of points to define either an arrow or box shape along a strand.\n        \"\"\"\n        if shape == 'box':\n            return [(self.start, 0), (self.end, 0), (self.end, 1), (self.start, 1)]\n        elif shape == 'arrow':\n            head_length = min(head_length_ratio * len(self), max_head_length)\n            head_width = head_width_ratio * arrow_shaft_width  # Head width relative to shaft\n            shaft_end = (self.end - head_length) if self.strand == 1 else (self.start + head_length)\n            return [\n                (self.start if self.strand == 1 else self.end, -arrow_shaft_width / 2),  # Start of shaft\n                (shaft_end, -arrow_shaft_width / 2),  # End of shaft, base of head\n                (shaft_end, -head_width / 2),  # Head tip, left\n                (self.end if self.strand == 1 else self.start, 0),  # Head tip, center\n                (shaft_end, head_width / 2),  # Head tip, right\n                (shaft_end, arrow_shaft_width / 2),  # End of shaft, base of head (top)\n                (self.start if self.strand == 1 else self.end, arrow_shaft_width / 2),  # Start of shaft (top)\n            ]\n        else:\n            raise ValueError(shape)\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Location.extract","title":"<code>extract(parent)</code>","text":"<p>Extracts a sequence from a parent object based on the location.</p> <p>:param parent: Parent object (<code>Seq</code>, <code>Record</code>, <code>Feature</code>) or dictionary of parent objects :return: Seq object</p> Source code in <code>eris/seq.py</code> <pre><code>def extract(self, parent: Union[Union['Seq', 'Record', 'Feature'], dict[str, Union['Seq', 'Record', 'Feature']]]) -&gt; 'Seq':\n    \"\"\"\n    Extracts a sequence from a parent object based on the location.\n\n    :param parent: Parent object (``Seq``, ``Record``, ``Feature``) or dictionary of parent objects\n    :return: Seq object\n    \"\"\"\n    new_seq = []\n    if isinstance(parent, dict):\n        if not (ref := parent.get(self.parent_id)):\n            raise LocationError(f'{self.parent_id=} not in parent dictionary')\n        new_seq.append(ref.seq[self] if not isinstance(ref, Seq) else ref[self])\n    else:\n        if self.parent_id and not isinstance(parent, Seq) and parent.id != self.parent_id:\n            raise LocationError(f'{self.parent_id=} does not match {parent.id=}')\n        new_seq.append(parent.seq[self] if not isinstance(parent, Seq) else parent[self])\n    if self.joins:\n        new_seq += (i.extract(parent) for i in self.joins)\n    if len(alphabet := {i.alphabet for i in new_seq}) &gt; 1:\n        raise LocationError('Cannot extract sequence from mixed alphabet types')\n    return Seq(''.join(map(str, new_seq)), alphabet.pop())\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Location.overlap","title":"<code>overlap(other)</code>","text":"<p>Returns the length of the overlap between two locations :param other: Location or HasLocation object</p> Source code in <code>eris/seq.py</code> <pre><code>def overlap(self, other: Union['Location', 'HasLocation']) -&gt; int:\n    \"\"\"\n    Returns the length of the overlap between two locations\n    :param other: Location or HasLocation object\n    \"\"\"\n    if isinstance(other, HasLocation):\n        other = other.location\n    if isinstance(other, Location):\n        return max(0, min(self.end, other.end) - max(self.start, other.start))\n    else:\n        raise TypeError(other)\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Qualifier","title":"<code>Qualifier</code>","text":"<p>Class to represent a qualifier as a key and value</p> <p>Attributes:</p> Name Type Description <code>key</code> <p>str</p> <code>value</code> <p>Any</p> Source code in <code>eris/seq.py</code> <pre><code>class Qualifier:\n    \"\"\"\n    Class to represent a qualifier as a key and value\n\n    Attributes:\n        key: str\n        value: Any\n    \"\"\"\n    def __init__(self, key: str, value: Any = None):\n        self.key = key\n        self.value = value if value != '' or value is not None else ''  # We still want zeroes\n\n    def __repr__(self):\n        return f\"{self.key}={self.value}\" if self.value != '' or self.value is not None else self.key\n\n    def __iter__(self) -&gt; Iterator[tuple[str, Any]]:\n        return iter((self.key, self.value))\n\n    def __str__(self):\n        return f\"{self.key}:{_TYPE2TAG[type(self.value)]}:{self.value}\"\n\n    def __eq__(self, other):\n        if isinstance(other, Qualifier):\n            return self.key == other.key and self.value == other.value\n        return False\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Record","title":"<code>Record</code>","text":"<p>Represents a sequence record.</p> <p>Attributes:</p> Name Type Description <code>id</code> <p>str</p> <code>seq</code> <p>The sequence of the record.</p> <code>desc</code> <p>A description of the record.</p> <code>qualifiers</code> <p>A list of Qualifier objects providing additional information about the record.</p> <code>features</code> <p>A list of Feature objects representing features on the sequence.</p> Source code in <code>eris/seq.py</code> <pre><code>class Record:\n    \"\"\"\n    Represents a sequence record.\n\n    Attributes:\n        id: str\n        seq: The sequence of the record.\n        desc: A description of the record.\n        qualifiers: A list of Qualifier objects providing additional information about the record.\n        features: A list of Feature objects representing features on the sequence.\n    \"\"\"\n\n    def __init__(self, id_: str, seq: Union[Seq, str], desc: str = None, qualifiers: list[Qualifier] = None,\n                 features: list['Feature'] = None):\n        self.id = id_\n        self.seq = seq if isinstance(seq, Seq) else Seq(seq)\n        self.desc = desc or ''\n        self.qualifiers = qualifiers or []\n        self.features = features or []  # TODO: Consider using a heapq for positional lookup\n\n    def __getitem__(self, item: Union[slice, HasLocation, Location]) -&gt; 'Record':\n        if isinstance(item, HasLocation):  # Convert HasLocation to Location\n            item = item.location\n        elif isinstance(item, slice):  # Convert slice to location\n            item = Location(item.start or 0, item.stop or len(self), 1)\n        elif not isinstance(item, Location):\n            raise TypeError(f\"Item must be a slice,a Location or object with a location attribute, not {item}\")\n        new_record = Record(f\"{self.id}_{item.start}-{item.end}\", self.seq[item], self.desc)\n        for feature in self.features:  # Assume features are sorted\n            if feature.location in item:\n                new_record.features.append(new_feature := feature.shift(-item.start))\n                new_feature.location.parent_id = new_record.id\n        return new_record\n\n    def __repr__(self) -&gt; str:\n        return f\"{self.id} {self.seq.__repr__()}\"\n\n    def __str__(self) -&gt; str:\n        return self.id\n\n    def __len__(self) -&gt; int:\n        return len(self.seq)\n\n    def __hash__(self) -&gt; int:\n        return hash(self.id)\n\n    def __eq__(self, other) -&gt; bool:\n        if isinstance(other, Record):\n            return self.id == other.id\n        return False\n\n    def __iter__(self) -&gt; Iterator['Feature']:\n        return iter(self.features)\n\n    def __format__(self, __format_spec: Literal['fasta', 'fna', 'ffn', 'faa', 'bed', 'gfa'] = '') -&gt; str:\n        if __format_spec == '':\n            return self.__str__()\n        elif __format_spec in {'fasta', 'fna'}:\n            return f\"&gt;{self.id}\\n{self.seq}\\n\"\n        elif __format_spec in {'faa', 'ffn'}:\n            return ''.join(format(i, __format_spec) for i in self.features)\n        elif __format_spec == 'bed':\n            return ''.join(f\"{self.id}\\t{format(i, __format_spec)}\" for i in self.features)\n        elif __format_spec == 'gfa':\n            # See: https://gfa-spec.github.io/GFA-spec/GFA1.html\n            return f\"S\\t{self.id}\\t{self.desc}\\t{self.seq}\\n\"\n        else:\n            raise NotImplementedError(f'Invalid format: {__format_spec}')\n\n    def __add__(self, other: 'Record') -&gt; 'Record':\n        if isinstance(other, Record):\n            new = Record(f\"{self.id}_{other.id}\", self.seq + other.seq, self.desc, [], [])\n            for feature in self.features:\n                new_feat = copy(feature)  # Creates a copy for the new record\n                new_feat.location.parent_id = new.id  # Update the ref ID\n\n            for feature in other.features:  # Other feature locations need to be updated\n                feature = feature.shift(len(self))  # Creates a new feature and location\n                feature.location.parent_id = new.id  # Update the ref ID\n                new.features.append(feature)\n\n            new.features.sort(key=attrgetter('location.start'))  # Sort features\n            return new\n        else:\n            raise TypeError(other)\n\n    def __radd__(self, other: 'Record') -&gt; 'Record':\n        return other.__add__(self)\n\n    def __iadd__(self, other: 'Record'):\n        if isinstance(other, Record):\n            self.id = f\"{self.id}_{other.id}\"  # Update the ref ID\n            for feature in self.features:\n                feature.location.parent_id = self.id  # Update the ref ID\n\n            for feature in other.features:\n                feature = feature.shift(len(self))  # Creates a new feature and location\n                feature.location.parent_id = self.id\n                self.features.append(feature)  # Update the ref ID\n\n            self.features.sort(key=attrgetter('location.start'))  # Sort features\n            self.seq += other.seq  # Now we can update the sequence\n            return self\n        else:\n            raise TypeError(other)\n\n    def __delslice__(self, i, j):\n        del self.seq[i:j]  # Remove the part of the sequence\n        self.features = []  # Reset the features\n        for feature in self.features:\n            if feature.location.end &lt;= i:\n                continue  # Feature is before the deleted part\n            elif feature.location.start &gt;= j:\n                self.features.append(feature.shift(-(j - i)))  # Adjust location\n            else:\n                del feature  # Feature overlaps the deleted part, remove it\n\n    @classmethod\n    def random(cls, id_: str = None, alphabet: Alphabet = DNA, rng: Random = None, gc: float = 0.5,\n               length: int = None, min_len: int = 10, max_len: int = 5000000) -&gt; 'Record':\n        \"\"\"\n        Generates a random record for testing purposes.\n\n        :param id_: ID of the record. If not provided, a random UUID will be used.\n        :param alphabet: Alphabet of the sequence.\n        :param rng: Random number generator.\n        :param gc: GC content of the sequence.\n        :param length: Length of the sequence. If not provided, a random length will be generated.\n        :param min_len: Minimum length of the sequence if length is not specified.\n        :param max_len: Maximum length of the sequence if length is not specified.\n        :return: A Record instance.\n        \"\"\"\n        return cls(id_ or str(uuid4()), Seq.random(alphabet, rng, gc, length, min_len, max_len))\n\n    def shred(self, rng: Random = None, n_breaks: int = None, break_points: list[int] = None\n              ) -&gt; Generator['Record', None, None]:\n        \"\"\"\n        Shreds the record into smaller records at the specified break points.\n\n        :param rng: Random number generator\n        :param n_breaks: The number of breaks to make in the record. If not provided, a random number of breaks will be\n            made between 1 and half the length of the record.\n        :param break_points: A list of break points to use. If not provided, random break points will be generated.\n        :return: A generator of smaller records\n        \"\"\"\n        if rng is None:\n            rng = RESOURCES.rng\n        if not n_breaks:\n            n_breaks = rng.randint(1, len(self) // 2)\n        if not break_points:\n            break_points = sorted([rng.randint(0, len(self)) for _ in range(n_breaks)])\n        previous_end = 0\n        for break_point in break_points:\n            yield self[previous_end:break_point]\n            previous_end = break_point\n        yield self[previous_end:]\n\n    def insert(self, other: 'Record', at: int, replace: bool = True) -&gt; 'Record':\n        \"\"\"\n        Inserts another record into this record at the specified position.\n\n        :param other: The record to insert.\n        :param at: The position to insert the other record at.\n        :param replace: Whether to replace the existing sequence at the insertion point with the inserted sequence.\n            If False, the inserted sequence will be inserted without removing any existing sequence.\n        :return: A new Record instance with the other record inserted.\n        \"\"\"\n        if not 0 &lt; at &lt; len(self):\n            raise IndexError(f'Cannot insert at {at}, must be between 0 and {len(self)}')\n        else:\n            new = self[:at] + other + self[at if not replace else at + len(other):]\n            return new\n\n    def translate(self, to_stop: bool = True, stop_symbol: str = \"*\", frame: Literal[0, 1, 2] = 0,\n                  gap_character: str = None) -&gt; 'Record':\n        \"\"\"\n        Translates the record to amino acid if it is a nucleotide sequence\n\n        :param to_stop: Boolean to stop translation at the first stop codon\n        :param stop_symbol: Character to resemble the stop codon\n        :param frame: Zero-based frame to begin translation from, must be one of 0, 1 or 2\n        :param gap_character: The gap character if performing a gapped-translation\n        \"\"\"\n        if self.seq.alphabet == 'DNA':\n            return self\n        else:\n            return Record(self.id, self.seq.translate(to_stop, stop_symbol, frame, gap_character), self.desc)\n\n    def as_edge_list(self) -&gt; Generator[Edge, None, None]:\n        \"\"\"\n        Yields edges of the record features to be used in a Graph.\n        The node attributes represent the feature strands, and the weight represents the distance between the\n        features. If the record is circular, the last feature is connected to the first feature.\n        \"\"\"\n        if len(self.features) == 0:\n            return None\n        else:\n            for position, to in enumerate(self.features):\n                if position &gt; 0:\n                    fr = self.features[position - 1]\n                    distance = to.location.start - fr.location.end\n                    yield Edge(fr.id, to.id, fr.location.strand, to.location.strand, distance)\n            if (topology := next((v for k, v in self.qualifiers if k == 'topology'), None)) and topology == 'circular':\n                fr, to = self.features[-1], self.features[0]\n                distance = (len(self) - fr.location.end) + to.location.start\n                yield Edge(fr.id, to.id, fr.location.strand, to.location.strand, distance)\n\n    def reverse_complement(self) -&gt; 'Record':\n        \"\"\"\n        Returns the reverse complement of the record.\n        \"\"\"\n        return Record(self.id, self.seq.reverse_complement(), self.desc, self.qualifiers,\n                      [f.reverse_complement(len(self)) for f in self.features[::-1]])\n\n    def add_features(self, *features: HasLocation):\n        \"\"\"\n        Adds features to the record.\n        :param features: Features to add to the record.\n        \"\"\"\n        self.features += features\n        self.features.sort(key=attrgetter('location.start'))\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Record.add_features","title":"<code>add_features(*features)</code>","text":"<p>Adds features to the record. :param features: Features to add to the record.</p> Source code in <code>eris/seq.py</code> <pre><code>def add_features(self, *features: HasLocation):\n    \"\"\"\n    Adds features to the record.\n    :param features: Features to add to the record.\n    \"\"\"\n    self.features += features\n    self.features.sort(key=attrgetter('location.start'))\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Record.as_edge_list","title":"<code>as_edge_list()</code>","text":"<p>Yields edges of the record features to be used in a Graph. The node attributes represent the feature strands, and the weight represents the distance between the features. If the record is circular, the last feature is connected to the first feature.</p> Source code in <code>eris/seq.py</code> <pre><code>def as_edge_list(self) -&gt; Generator[Edge, None, None]:\n    \"\"\"\n    Yields edges of the record features to be used in a Graph.\n    The node attributes represent the feature strands, and the weight represents the distance between the\n    features. If the record is circular, the last feature is connected to the first feature.\n    \"\"\"\n    if len(self.features) == 0:\n        return None\n    else:\n        for position, to in enumerate(self.features):\n            if position &gt; 0:\n                fr = self.features[position - 1]\n                distance = to.location.start - fr.location.end\n                yield Edge(fr.id, to.id, fr.location.strand, to.location.strand, distance)\n        if (topology := next((v for k, v in self.qualifiers if k == 'topology'), None)) and topology == 'circular':\n            fr, to = self.features[-1], self.features[0]\n            distance = (len(self) - fr.location.end) + to.location.start\n            yield Edge(fr.id, to.id, fr.location.strand, to.location.strand, distance)\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Record.insert","title":"<code>insert(other, at, replace=True)</code>","text":"<p>Inserts another record into this record at the specified position.</p> <p>:param other: The record to insert. :param at: The position to insert the other record at. :param replace: Whether to replace the existing sequence at the insertion point with the inserted sequence.     If False, the inserted sequence will be inserted without removing any existing sequence. :return: A new Record instance with the other record inserted.</p> Source code in <code>eris/seq.py</code> <pre><code>def insert(self, other: 'Record', at: int, replace: bool = True) -&gt; 'Record':\n    \"\"\"\n    Inserts another record into this record at the specified position.\n\n    :param other: The record to insert.\n    :param at: The position to insert the other record at.\n    :param replace: Whether to replace the existing sequence at the insertion point with the inserted sequence.\n        If False, the inserted sequence will be inserted without removing any existing sequence.\n    :return: A new Record instance with the other record inserted.\n    \"\"\"\n    if not 0 &lt; at &lt; len(self):\n        raise IndexError(f'Cannot insert at {at}, must be between 0 and {len(self)}')\n    else:\n        new = self[:at] + other + self[at if not replace else at + len(other):]\n        return new\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Record.random","title":"<code>random(id_=None, alphabet=DNA, rng=None, gc=0.5, length=None, min_len=10, max_len=5000000)</code>  <code>classmethod</code>","text":"<p>Generates a random record for testing purposes.</p> <p>:param id_: ID of the record. If not provided, a random UUID will be used. :param alphabet: Alphabet of the sequence. :param rng: Random number generator. :param gc: GC content of the sequence. :param length: Length of the sequence. If not provided, a random length will be generated. :param min_len: Minimum length of the sequence if length is not specified. :param max_len: Maximum length of the sequence if length is not specified. :return: A Record instance.</p> Source code in <code>eris/seq.py</code> <pre><code>@classmethod\ndef random(cls, id_: str = None, alphabet: Alphabet = DNA, rng: Random = None, gc: float = 0.5,\n           length: int = None, min_len: int = 10, max_len: int = 5000000) -&gt; 'Record':\n    \"\"\"\n    Generates a random record for testing purposes.\n\n    :param id_: ID of the record. If not provided, a random UUID will be used.\n    :param alphabet: Alphabet of the sequence.\n    :param rng: Random number generator.\n    :param gc: GC content of the sequence.\n    :param length: Length of the sequence. If not provided, a random length will be generated.\n    :param min_len: Minimum length of the sequence if length is not specified.\n    :param max_len: Maximum length of the sequence if length is not specified.\n    :return: A Record instance.\n    \"\"\"\n    return cls(id_ or str(uuid4()), Seq.random(alphabet, rng, gc, length, min_len, max_len))\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Record.reverse_complement","title":"<code>reverse_complement()</code>","text":"<p>Returns the reverse complement of the record.</p> Source code in <code>eris/seq.py</code> <pre><code>def reverse_complement(self) -&gt; 'Record':\n    \"\"\"\n    Returns the reverse complement of the record.\n    \"\"\"\n    return Record(self.id, self.seq.reverse_complement(), self.desc, self.qualifiers,\n                  [f.reverse_complement(len(self)) for f in self.features[::-1]])\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Record.shred","title":"<code>shred(rng=None, n_breaks=None, break_points=None)</code>","text":"<p>Shreds the record into smaller records at the specified break points.</p> <p>:param rng: Random number generator :param n_breaks: The number of breaks to make in the record. If not provided, a random number of breaks will be     made between 1 and half the length of the record. :param break_points: A list of break points to use. If not provided, random break points will be generated. :return: A generator of smaller records</p> Source code in <code>eris/seq.py</code> <pre><code>def shred(self, rng: Random = None, n_breaks: int = None, break_points: list[int] = None\n          ) -&gt; Generator['Record', None, None]:\n    \"\"\"\n    Shreds the record into smaller records at the specified break points.\n\n    :param rng: Random number generator\n    :param n_breaks: The number of breaks to make in the record. If not provided, a random number of breaks will be\n        made between 1 and half the length of the record.\n    :param break_points: A list of break points to use. If not provided, random break points will be generated.\n    :return: A generator of smaller records\n    \"\"\"\n    if rng is None:\n        rng = RESOURCES.rng\n    if not n_breaks:\n        n_breaks = rng.randint(1, len(self) // 2)\n    if not break_points:\n        break_points = sorted([rng.randint(0, len(self)) for _ in range(n_breaks)])\n    previous_end = 0\n    for break_point in break_points:\n        yield self[previous_end:break_point]\n        previous_end = break_point\n    yield self[previous_end:]\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Record.translate","title":"<code>translate(to_stop=True, stop_symbol='*', frame=0, gap_character=None)</code>","text":"<p>Translates the record to amino acid if it is a nucleotide sequence</p> <p>:param to_stop: Boolean to stop translation at the first stop codon :param stop_symbol: Character to resemble the stop codon :param frame: Zero-based frame to begin translation from, must be one of 0, 1 or 2 :param gap_character: The gap character if performing a gapped-translation</p> Source code in <code>eris/seq.py</code> <pre><code>def translate(self, to_stop: bool = True, stop_symbol: str = \"*\", frame: Literal[0, 1, 2] = 0,\n              gap_character: str = None) -&gt; 'Record':\n    \"\"\"\n    Translates the record to amino acid if it is a nucleotide sequence\n\n    :param to_stop: Boolean to stop translation at the first stop codon\n    :param stop_symbol: Character to resemble the stop codon\n    :param frame: Zero-based frame to begin translation from, must be one of 0, 1 or 2\n    :param gap_character: The gap character if performing a gapped-translation\n    \"\"\"\n    if self.seq.alphabet == 'DNA':\n        return self\n    else:\n        return Record(self.id, self.seq.translate(to_stop, stop_symbol, frame, gap_character), self.desc)\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Seq","title":"<code>Seq</code>","text":"<p>Class representing a sequence.</p> <p>:param seq: Sequence string :param alphabet: alphabet (DNA or Amino), attempts to guess if not provided</p> Source code in <code>eris/seq.py</code> <pre><code>class Seq:\n    \"\"\"\n    Class representing a sequence.\n\n    :param seq: Sequence string\n    :param alphabet: alphabet (DNA or Amino), attempts to guess if not provided\n    \"\"\"\n    def __init__(self, seq: str, alphabet: Literal['DNA', 'Amino'] = None):\n        if len(seq := seq.strip().upper()) &lt; 1:\n            raise SeqError(\"Seq must be &gt;=1 character(s)\")\n        self._seq = seq\n        self.alphabet = alphabet or ('DNA' if self._seq in DNA else 'Amino')\n\n    def __repr__(self):\n        return f\"{self.alphabet}({self._seq})\" if len(self._seq) &lt; 13 else f\"{self.alphabet}({self._seq[:5]}...{self._seq[-5:]})\"\n\n    def __len__(self):\n        return len(self._seq)\n\n    def __hash__(self) -&gt; int:\n        return hash(self._seq)\n\n    def __eq__(self, other):\n        if isinstance(other, Seq):\n            return self._seq == other._seq\n        return False\n\n    def __str__(self):\n        return self._seq\n\n    def __bytes__(self):\n        return self._seq.encode()\n\n    def __iter__(self):\n        return iter(self._seq)\n\n    def __contains__(self, item: str):\n        return item in self._seq\n\n    def __reversed__(self) -&gt; 'Seq':\n        return Seq(self._seq[::-1], self.alphabet)\n\n    def __add__(self, other: Union[str, 'Seq']) -&gt; 'Seq':\n        if isinstance(other, Seq):\n            assert self.alphabet == other.alphabet, SeqError('Both sequences need to be of the same alphabet')\n            return Seq(self._seq + str(other), self.alphabet)\n        elif isinstance(other, str):\n            return Seq(self._seq + other, self.alphabet)\n        else:\n            raise TypeError(other)\n\n    def __radd__(self, other: Union[str, 'Seq']) -&gt; 'Seq':\n        return self.__add__(other)\n\n    def __iadd__(self, other: Union[str, 'Seq']):\n        if isinstance(other, Seq):\n            assert self.alphabet == other.alphabet, SeqError('Both sequences need to be of the same alphabet')\n            self._seq += str(other)\n            return self\n        elif isinstance(other, str):\n            self._seq += other\n            return self\n        else:\n            raise TypeError(other)\n\n    def __getitem__(self, item: Union[slice, int, Location, HasLocation]) -&gt; 'Seq':\n        \"\"\"Quick method of slicing the sequence and reverse complementing if necessary\"\"\"\n        if isinstance(item, (slice, int)):\n            return Seq(self._seq[item], self.alphabet)\n        elif isinstance(item, (Location, HasLocation)):\n            if isinstance(item, HasLocation):\n                item = item.location\n            new = Seq(self._seq[item.start:item.end], self.alphabet)\n            return new if (item.strand == 1) else new.reverse_complement()\n        else:\n            raise TypeError(item)\n\n    def __call__(self) -&gt; str:\n        return self._seq\n\n    @classmethod\n    def random(\n            cls, alphabet: Alphabet, rng: Random = None, gc: float = 0.5, length: int = None,\n            min_len: int = 10, max_len: int = 5000000) -&gt; 'Seq':\n        if rng is None:\n            rng = RESOURCES.rng\n        if isinstance(alphabet, _DNA):\n            at = (1 - gc) / 2\n            gc /= 2\n            return cls(''.join(rng.choices(alphabet, weights=[at, gc, at, gc], k=length or rng.randint(min_len, max_len))), 'DNA')\n        else:\n            return cls(''.join(rng.choice(alphabet) for _ in range(rng.randint(min_len, max_len))), 'Amino')\n\n    def replace(self, *args, **kwargs):\n        return Seq(self._seq.replace(*args, **kwargs), self.alphabet)\n\n    def reverse_complement(self) -&gt; 'Seq':\n        \"\"\"Reverse complements the sequence if it is a nucleotide sequence\"\"\"\n        if self.alphabet == 'DNA':\n            return Seq(self._seq.translate(DNA.complement)[::-1], 'DNA')\n        return self\n\n    def translate(self, to_stop: bool = True, stop_symbol: str = \"*\", frame: Literal[0, 1, 2] = 0,\n                  gap_character: str = None) -&gt; 'Seq':\n        \"\"\"\n        Translates the sequence to amino acid if it is a nucleotide sequence\n\n        :param to_stop: Boolean to stop translation at the first stop codon\n        :param stop_symbol: Character to resemble the stop codon\n        :param frame: Zero-based frame to begin translation from, must be one of 0, 1 or 2\n        :param gap_character: The gap character if performing a gapped-translation\n        \"\"\"\n        if self.alphabet == 'DNA':  # Only need to translate DNA\n            if len(self._seq) &lt; 3:\n                raise TranslationError(f'Cannot translate sequence of length {len(self._seq)}')\n            protein = []\n            for i in range(frame, len(self), 3):  # Iterate over seq codons (chunks of 3)\n                if len(codon := self._seq[i:i + 3]) &lt; 3:\n                    break  # We can't translate chunks less than 3 (not codons) so break here\n                if gap_character and gap_character in codon:\n                    protein.append(gap_character)\n                    continue\n                protein.append(residue := DNA.codons.get(codon, stop_symbol))  # If lookup fails (get == None), assume stop codon\n                if to_stop and residue == stop_symbol:\n                    break  # Break if to_stop == True\n            if protein == ['*']:\n                raise TranslationError('Translation consists of a single stop codon')\n            return Seq(''.join(protein), 'Amino')\n        return self  # alphabet == 'Amino' so return self\n\n    def GC(self) -&gt; float:\n        \"\"\"\n        Returns the GC content of the sequence\n        \"\"\"\n        return sum(1 for i in self._seq if i in {'G', 'C'}) / len(self._seq)\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Seq.GC","title":"<code>GC()</code>","text":"<p>Returns the GC content of the sequence</p> Source code in <code>eris/seq.py</code> <pre><code>def GC(self) -&gt; float:\n    \"\"\"\n    Returns the GC content of the sequence\n    \"\"\"\n    return sum(1 for i in self._seq if i in {'G', 'C'}) / len(self._seq)\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Seq.__getitem__","title":"<code>__getitem__(item)</code>","text":"<p>Quick method of slicing the sequence and reverse complementing if necessary</p> Source code in <code>eris/seq.py</code> <pre><code>def __getitem__(self, item: Union[slice, int, Location, HasLocation]) -&gt; 'Seq':\n    \"\"\"Quick method of slicing the sequence and reverse complementing if necessary\"\"\"\n    if isinstance(item, (slice, int)):\n        return Seq(self._seq[item], self.alphabet)\n    elif isinstance(item, (Location, HasLocation)):\n        if isinstance(item, HasLocation):\n            item = item.location\n        new = Seq(self._seq[item.start:item.end], self.alphabet)\n        return new if (item.strand == 1) else new.reverse_complement()\n    else:\n        raise TypeError(item)\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Seq.reverse_complement","title":"<code>reverse_complement()</code>","text":"<p>Reverse complements the sequence if it is a nucleotide sequence</p> Source code in <code>eris/seq.py</code> <pre><code>def reverse_complement(self) -&gt; 'Seq':\n    \"\"\"Reverse complements the sequence if it is a nucleotide sequence\"\"\"\n    if self.alphabet == 'DNA':\n        return Seq(self._seq.translate(DNA.complement)[::-1], 'DNA')\n    return self\n</code></pre>"},{"location":"reference/eris/seq/#eris.seq.Seq.translate","title":"<code>translate(to_stop=True, stop_symbol='*', frame=0, gap_character=None)</code>","text":"<p>Translates the sequence to amino acid if it is a nucleotide sequence</p> <p>:param to_stop: Boolean to stop translation at the first stop codon :param stop_symbol: Character to resemble the stop codon :param frame: Zero-based frame to begin translation from, must be one of 0, 1 or 2 :param gap_character: The gap character if performing a gapped-translation</p> Source code in <code>eris/seq.py</code> <pre><code>def translate(self, to_stop: bool = True, stop_symbol: str = \"*\", frame: Literal[0, 1, 2] = 0,\n              gap_character: str = None) -&gt; 'Seq':\n    \"\"\"\n    Translates the sequence to amino acid if it is a nucleotide sequence\n\n    :param to_stop: Boolean to stop translation at the first stop codon\n    :param stop_symbol: Character to resemble the stop codon\n    :param frame: Zero-based frame to begin translation from, must be one of 0, 1 or 2\n    :param gap_character: The gap character if performing a gapped-translation\n    \"\"\"\n    if self.alphabet == 'DNA':  # Only need to translate DNA\n        if len(self._seq) &lt; 3:\n            raise TranslationError(f'Cannot translate sequence of length {len(self._seq)}')\n        protein = []\n        for i in range(frame, len(self), 3):  # Iterate over seq codons (chunks of 3)\n            if len(codon := self._seq[i:i + 3]) &lt; 3:\n                break  # We can't translate chunks less than 3 (not codons) so break here\n            if gap_character and gap_character in codon:\n                protein.append(gap_character)\n                continue\n            protein.append(residue := DNA.codons.get(codon, stop_symbol))  # If lookup fails (get == None), assume stop codon\n            if to_stop and residue == stop_symbol:\n                break  # Break if to_stop == True\n        if protein == ['*']:\n            raise TranslationError('Translation consists of a single stop codon')\n        return Seq(''.join(protein), 'Amino')\n    return self  # alphabet == 'Amino' so return self\n</code></pre>"},{"location":"reference/eris/utils/","title":"eris.utils","text":"<p>Module containing various utility functions and classes.</p>"},{"location":"reference/eris/utils/#eris.utils.Config","title":"<code>Config</code>  <code>dataclass</code>","text":"<p>Config parent class that can conveniently set attributes from CLI args</p> Source code in <code>eris/utils.py</code> <pre><code>@dataclass  # (kw_only=True) https://medium.com/@aniscampos/python-dataclass-inheritance-finally-686eaf60fbb5\nclass Config:\n    \"\"\"\n    Config parent class that can conveniently set attributes from CLI args\n    \"\"\"\n\n    @classmethod\n    def from_args(cls, args: Namespace):\n        \"\"\"\n        Sets attributes of the class from a Namespace object (e.g. from argparse)\n\n        Parameters\n        ----------\n        args : :class:`argparse.Namespace`\n            :class:`argparse.Namespace` object containing attributes to set\n\n        Returns\n        -------\n        cls\n            Class instance with attributes set from args\n\n        \"\"\"\n        return cls(**{f: getattr(args, f) for f in asdict(cls) if hasattr(args, f)})\n</code></pre>"},{"location":"reference/eris/utils/#eris.utils.Config.from_args","title":"<code>from_args(args)</code>  <code>classmethod</code>","text":"<p>Sets attributes of the class from a Namespace object (e.g. from argparse)</p>"},{"location":"reference/eris/utils/#eris.utils.Config.from_args--parameters","title":"Parameters","text":"<p>args : :class:<code>argparse.Namespace</code>     :class:<code>argparse.Namespace</code> object containing attributes to set</p>"},{"location":"reference/eris/utils/#eris.utils.Config.from_args--returns","title":"Returns","text":"<p>cls     Class instance with attributes set from args</p> Source code in <code>eris/utils.py</code> <pre><code>@classmethod\ndef from_args(cls, args: Namespace):\n    \"\"\"\n    Sets attributes of the class from a Namespace object (e.g. from argparse)\n\n    Parameters\n    ----------\n    args : :class:`argparse.Namespace`\n        :class:`argparse.Namespace` object containing attributes to set\n\n    Returns\n    -------\n    cls\n        Class instance with attributes set from args\n\n    \"\"\"\n    return cls(**{f: getattr(args, f) for f in asdict(cls) if hasattr(args, f)})\n</code></pre>"},{"location":"reference/eris/utils/#eris.utils.bold","title":"<code>bold(text)</code>","text":"<p>Makes text bold in the terminal.</p> <p>:param text: Text to make bold. :return: Bold text.</p> Source code in <code>eris/utils.py</code> <pre><code>def bold(text: str):\n    \"\"\"\n    Makes text bold in the terminal.\n\n    :param text: Text to make bold.\n    :return: Bold text.\n    \"\"\"\n    return f\"\\033[1m{text}\\033[0m\"\n</code></pre>"},{"location":"reference/eris/utils/#eris.utils.decompress","title":"<code>decompress(buffer, method='magic')</code>","text":"<p>Decompresses a buffer of bytes using the appropriate decompression function based on the magic bytes at the beginning of the data.</p> <p>:param buffer: Buffer of bytes to decompress. :param method: Method to determine how to decompress buffer; <code>magic</code> will determine from the magic bytes at the                beginning of the buffer, the other options force the buffer type and should be one of                <code>uncompressed</code>, <code>gz</code>, <code>bz2</code>, <code>xz</code> or <code>zst</code> (if installed). :return: Decompressed buffer of bytes.</p> Source code in <code>eris/utils.py</code> <pre><code>def decompress(\n        buffer: bytes, method: Literal['magic', 'uncompressed', 'gz', 'bz2', 'xz', 'zst'] = 'magic'\n) -&gt; bytes:\n    \"\"\"\n    Decompresses a buffer of bytes using the appropriate decompression function based on the magic bytes at the\n    beginning of the data.\n\n    :param buffer: Buffer of bytes to decompress.\n    :param method: Method to determine how to decompress buffer; ``magic`` will determine from the magic bytes at the\n                   beginning of the buffer, the other options force the buffer type and should be one of\n                   ``uncompressed``, ``gz``, ``bz2``, ``xz`` or ``zst`` (if installed).\n    :return: Decompressed buffer of bytes.\n    \"\"\"\n    if method not in {'magic', 'uncompressed', 'gz', 'bz2', 'xz', 'zst'}:\n        raise ValueError(f'Invalid {method=}')\n\n    if method in {'uncompressed', 'gz', 'bz2', 'xz', 'zst'}:\n        if method == 'zst' and 'zstandard' not in RESOURCES.optional_packages:\n            raise ImportError(f'Package to deal with {method=} not imported, is it installed?')\n        return buffer if method == 'uncompressed' else _DECOMPRESS[method](buffer)\n\n    elif method == 'magic':  # Use the empirical method using magic bytes\n        first_bytes = buffer[0:_MIN_N_BYTES]\n        method = 'uncompressed'\n        for magic, compression in _MAGIC_BYTES.items():\n            if first_bytes.startswith(magic):\n                method = compression\n                break\n        return buffer if method == 'uncompressed' else _DECOMPRESS[method](buffer)\n</code></pre>"},{"location":"reference/eris/utils/#eris.utils.download","title":"<code>download(url, dest=None, data=None, encode_data=False)</code>","text":"<p>Downloads a file from a URL to a destination or returns the data as bytes.</p> <p>:param url: URL to download from. :param dest: Destination path to save the file to. If None, returns the data as bytes. :return: Path to the downloaded file or the data as bytes. :raises ValueError: If no data is written to the destination file.</p> Source code in <code>eris/utils.py</code> <pre><code>def download(url: Union[str, Request], dest: Union[str, Path] = None, data = None, encode_data: bool = False) -&gt; Union[Path, bytes, None]:\n    \"\"\"\n    Downloads a file from a URL to a destination or returns the data as bytes.\n\n    :param url: URL to download from.\n    :param dest: Destination path to save the file to. If None, returns the data as bytes.\n    :return: Path to the downloaded file or the data as bytes.\n    :raises ValueError: If no data is written to the destination file.\n    \"\"\"\n    if data and encode_data:\n        data = urlencode(data).encode('utf-8')\n    if not isinstance(url, Request):\n        url = Request(url, headers={'User-Agent': 'Mozilla/5.0'}, data=data)\n    response = urlopen(url)\n    if dest:\n        with open(dest, mode='wb') as handle:\n            handle.write(response.read())\n        if (dest := Path(dest)).stat().st_size == 0:\n            dest.unlink()\n            raise ValueError('No data written')\n        return dest\n    else:\n        return response.read()\n</code></pre>"},{"location":"reference/eris/utils/#eris.utils.find_executable_binaries","title":"<code>find_executable_binaries(*programs)</code>","text":"<p>Check if programs are installed and executable</p> <p>:param programs: List of programs to check :return: Generator of Path objects for each program found</p> Source code in <code>eris/utils.py</code> <pre><code>def find_executable_binaries(*programs: str) -&gt; Generator[Path, None, None]:\n    \"\"\"\n    Check if programs are installed and executable\n\n    :param programs: List of programs to check\n    :return: Generator of Path objects for each program found\n    \"\"\"\n    programs, found = set(programs), 0\n    while len(programs) &gt; found:\n        for path in map(Path, environ[\"PATH\"].split(pathsep)):\n            if path.is_dir():\n                for binary in path.iterdir():\n                    if binary.name in programs and access(binary, X_OK):\n                        found += 1\n                        yield binary\n</code></pre>"},{"location":"reference/eris/utils/#eris.utils.get_logo","title":"<code>get_logo(message)</code>","text":"<p>Returns the eris logo with a message centered below it.</p> <p>:param message: Message to display below the logo. :param width: Width of the logo. :return: Formatted logo string.</p> Source code in <code>eris/utils.py</code> <pre><code>def get_logo(message: str) -&gt; str:  # 43 is the width of the logo\n    \"\"\"\n    Returns the eris logo with a message centered below it.\n\n    :param message: Message to display below the logo.\n    :param width: Width of the logo.\n    :return: Formatted logo string.\n    \"\"\"\n    logo = '========================|&gt; eris |&gt;========================'\n    return f\"\\033[1;35m{logo}\\n{message.center(len(logo))}\\033[0m\"\n</code></pre>"},{"location":"reference/eris/utils/#eris.utils.grouper","title":"<code>grouper(iterable, key)</code>","text":"<p>Shortcut for sorting and grouping</p> Source code in <code>eris/utils.py</code> <pre><code>def grouper(iterable, key):\n    \"\"\"Shortcut for sorting and grouping\"\"\"\n    yield from groupby(sorted(iterable, key=attrgetter(key)), key=attrgetter(key))\n</code></pre>"},{"location":"reference/eris/utils/#eris.utils.is_non_empty_file","title":"<code>is_non_empty_file(file, min_size=1)</code>","text":"<p>Checks if a file exists, is a file, and is non-empty (optionally above a minimum size).</p> <p>:param file: Path to the file to check. :param min_size: Minimum size of the file in bytes. :return: True if the file exists, is a file, and is non-empty, False otherwise.</p> Source code in <code>eris/utils.py</code> <pre><code>def is_non_empty_file(file: Union[str, Path], min_size: int = 1) -&gt; bool:\n    \"\"\"\n    Checks if a file exists, is a file, and is non-empty (optionally above a minimum size).\n\n    :param file: Path to the file to check.\n    :param min_size: Minimum size of the file in bytes.\n    :return: True if the file exists, is a file, and is non-empty, False otherwise.\n    \"\"\"\n    if not isinstance(file, Path):\n        file = Path(file)\n    if file.exists() and file.is_file():\n        return file.stat().st_size &gt;= min_size\n    else:\n        return False\n</code></pre>"},{"location":"reference/eris/utils/#eris.utils.write_to_file_or_directory","title":"<code>write_to_file_or_directory(path, mode='at')</code>","text":"<p>Writes to a file or creates a directory based on the provided path.</p> <p>If the path is '-' or 'stdout', it returns stdout. If the path has a suffix, it's treated as a file and opened for appending. If the path has no suffix, it's treated as a directory and created if it doesn't exist.</p> <p>:param path: The path to the file or directory. :param mode: The mode to open the file in if it's a file. :return: A file handle (IO) if a file is specified, or a Path object if a directory is specified.</p> Source code in <code>eris/utils.py</code> <pre><code>def write_to_file_or_directory(path: Union[str, Path, IO], mode: str = 'at') -&gt; Union[Path, IO]:\n    \"\"\"\n    Writes to a file or creates a directory based on the provided path.\n\n    If the path is '-' or 'stdout', it returns stdout.\n    If the path has a suffix, it's treated as a file and opened for appending.\n    If the path has no suffix, it's treated as a directory and created if it doesn't exist.\n\n    :param path: The path to the file or directory.\n    :param mode: The mode to open the file in if it's a file.\n    :return: A file handle (IO) if a file is specified, or a Path object if a directory is specified.\n    \"\"\"\n    if isinstance(path, IOBase):\n        return path\n    if path in {'-', 'stdout'}:  # If the path is '-', return stdout\n        return stdout\n    if not isinstance(path, Path):  # Coerce to Path object\n        path = Path(path)\n    if path.suffix:  # If the path has an extension, it's probably a file\n        # NB: We can't use is_file or is_dir because it may not exist yet, `open()` will create or append\n        return open(path, mode)  # Open the file\n    else:\n        path.mkdir(exist_ok=True, parents=True)  # Create the directory if it doesn't exist\n    return path\n</code></pre>"},{"location":"reference/eris/utils/#eris.utils.xopen","title":"<code>xopen(file, method='magic', **open_args)</code>","text":"<p>Opens a file with the appropriate open function based on the magic bytes at the beginning of the data. Inspired by <code>xopen &lt;https://pypi.org/project/xopen/&gt;</code>_</p> <p>:param file: Path to file for opening as a string or Path object. :param method: Method to determine how to open file; <code>guess</code> will guess from the file extension, <code>magic</code>                will determine from the magic bytes at the beginning of the file, the other options force the file                type and should be one of <code>uncompressed</code>, <code>gz</code>, <code>bz2</code>, <code>xz</code> or <code>zst</code> (if installed). :param open_args: Additional keyword arguments to pass to the open function. :return: File handle in text or binary mode depending on the arguments passed to the open function.</p> Source code in <code>eris/utils.py</code> <pre><code>def xopen(\n        file: Union[str, Path],\n        method: Literal['magic', 'guess', 'uncompressed', 'gz', 'bz2', 'xz', 'zst'] = 'magic',\n        **open_args\n) -&gt; IO:\n    \"\"\"\n    Opens a file with the appropriate open function based on the magic bytes at the beginning of the data.\n    Inspired by `xopen &lt;https://pypi.org/project/xopen/&gt;`_\n\n    :param file: Path to file for opening as a string or Path object.\n    :param method: Method to determine how to open file; ``guess`` will guess from the file extension, ``magic``\n                   will determine from the magic bytes at the beginning of the file, the other options force the file\n                   type and should be one of ``uncompressed``, ``gz``, ``bz2``, ``xz`` or ``zst`` (if installed).\n    :param open_args: Additional keyword arguments to pass to the open function.\n    :return: File handle in text or binary mode depending on the arguments passed to the open function.\n    \"\"\"\n    if method not in {'magic', 'guess', 'uncompressed', 'gz', 'bz2', 'xz', 'zst'}:\n        raise ValueError(f'Invalid {method=}')\n\n    if method in {'uncompressed', 'gz', 'bz2', 'xz', 'zst'}:\n        if method == 'zst' and 'zstandard' not in RESOURCES.optional_packages:\n            raise ImportError(f'Package to deal with {method=} not imported, is it installed?')\n        return _OPEN.get(method, open)(file, **open_args)\n\n    elif method == 'magic':  # Use the empirical method using magic bytes\n        with open(file, 'rb') as f:  # Open the file to read bytes\n            first_bytes = f.read(_MIN_N_BYTES)  # Get the bytes necessary to guess the compression type\n        method = 'uncompressed'\n        for magic, compression in _MAGIC_BYTES.items():\n            if first_bytes.startswith(magic):\n                method = compression\n                break\n        return _OPEN.get(method, open)(file, **open_args)\n\n    elif method == 'guess':\n        if not isinstance(file, Path):\n            file = Path(file)\n        return _OPEN.get(file.suffix, open)(file, **open_args)\n</code></pre>"}]}